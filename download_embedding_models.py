#!/usr/bin/env python3
"""
HuggingFaceåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Apple M4 Proã®Metal GPUåŠ é€Ÿã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã€ãƒ›ã‚¹ãƒˆã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

import os
import sys
from pathlib import Path
from sentence_transformers import SentenceTransformer
import torch

def check_metal_gpu():
    """Metal GPUï¼ˆApple Siliconï¼‰ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        if hasattr(torch.backends, "mps") and torch.backends.mps.is_available() and torch.backends.mps.is_built():
            print("âœ… Metal GPU (Apple Silicon) ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            return "mps"
        elif torch.cuda.is_available():
            print("âœ… CUDA GPU ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            return "cuda"
        else:
            print("âš ï¸  CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
            return "cpu"
    except ImportError:
        print("âš ï¸  PyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return "cpu"

def download_embedding_model(model_name, local_path):
    """HuggingFaceåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        print(f"ğŸ“¥ {model_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        local_path.mkdir(parents=True, exist_ok=True)
        
        # SentenceTransformerã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        model = SentenceTransformer(model_name)
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã«ä¿å­˜
        model.save(str(local_path))
        
        print(f"âœ… {model_name} ã‚’ {local_path} ã«ä¿å­˜å®Œäº†")
        return True
        
    except Exception as e:
        print(f"âŒ {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ HuggingFaceåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹")
    
    # GPUåˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    device = check_metal_gpu()
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    models_to_download = {
        "BAAI/bge-small-en-v1.5": "models/bge-small-en-v1.5",
        "BAAI/bge-large-en-v1.5": "models/bge-large-en-v1.5", 
        "sentence-transformers/all-MiniLM-L6-v2": "models/all-MiniLM-L6-v2",
        "sentence-transformers/all-mpnet-base-v2": "models/all-mpnet-base-v2",
        "sentence-transformers/multi-qa-MiniLM-L6-cos-v1": "models/multi-qa-MiniLM-L6-cos-v1",
        "sentence-transformers/multi-qa-mpnet-base-dot-v1": "models/multi-qa-mpnet-base-dot-v1",
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2": "models/paraphrase-multilingual-MiniLM-L12-v2",
        "sentence-transformers/distiluse-base-multilingual-cased-v2": "models/distiluse-base-multilingual-cased-v2",
        "sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens": "models/xlm-r-100langs-bert-base-nli-stsb-mean-tokens"
    }
    
    # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
    base_dir = Path(__file__).parent / "local_models"
    base_dir.mkdir(exist_ok=True)
    
    success_count = 0
    total_count = len(models_to_download)
    
    print(f"ğŸ“Š {total_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
    
    for model_name, local_subpath in models_to_download.items():
        local_path = base_dir / local_subpath
        
        # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        if local_path.exists() and any(local_path.iterdir()):
            print(f"â­ï¸  {model_name} ã¯æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ ({local_path})")
            success_count += 1
            continue
            
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if download_embedding_model(model_name, local_path):
            success_count += 1
        
        print()  # ç©ºè¡Œã§åŒºåˆ‡ã‚Š
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 60)
    print(f"ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ: {success_count}/{total_count} æˆåŠŸ")
    print(f"ğŸ¯ GPUåŠ é€Ÿ: {device.upper()}")
    print(f"ğŸ“ ä¿å­˜å…ˆ: {base_dir}")
    
    if success_count == total_count:
        print("ğŸ‰ å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ’¡ ã“ã‚Œã§åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚‚GPUåŠ é€ŸãŒåˆ©ç”¨ã§ãã¾ã™ã€‚")
    else:
        print(f"âš ï¸  {total_count - success_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
    return success_count == total_count

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
