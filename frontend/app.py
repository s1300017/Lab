from datetime import datetime
from pytz import timezone

def jst_now_str():
    return datetime.now(timezone('Asia/Tokyo')).strftime('%Y-%m-%d %H:%M:%S JST')

import os
import json
import streamlit as st
import streamlit.components.v1 as components
import base64
import json
import pandas as pd
import plotly.express as px
import requests
from typing import List, Dict, Any, Optional, Tuple, Literal, Union
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import plotly.graph_objects as go  # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç­‰ã§ä½¿ç”¨
from openai import OpenAI
from dotenv import load_dotenv
import io
import zipfile
from datetime import datetime
import tempfile
import shutil
import traceback

# ---# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
def get_japanese_font():
    """åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œå‡ºã—ã¦è¿”ã™"""
    try:
        # ä¸€èˆ¬çš„ãªæ—¥æœ¬èªå¯¾å¿œãƒ•ã‚©ãƒ³ãƒˆã®å„ªå…ˆé †ä½
        font_preferences = [
            'IPAexGothic', 'IPAGothic', 'Noto Sans CJK JP', 'Noto Sans JP',
            'Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Meiryo', 'MS Gothic',
            'Yu Gothic', 'TakaoGothic', 'VL Gothic', 'Arial Unicode MS', 'sans-serif'
        ]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—
        import matplotlib.font_manager as fm
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‹ã‚‰å„ªå…ˆé †ã«é¸æŠ
        for font in font_preferences:
            if any(font.lower() in f.lower() for f in available_fonts):
                return font
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ã‚»ãƒªãƒ•ãƒ•ã‚©ãƒ³ãƒˆ
        return 'sans-serif'
    except Exception as e:
        print(f"ãƒ•ã‚©ãƒ³ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return 'sans-serif'

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®š
japanese_font = get_japanese_font()

def plot_overlap_comparison(results_df: pd.DataFrame) -> None:
    """
    ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã”ã¨ã®è©•ä¾¡æŒ‡æ¨™ã‚’æ¯”è¼ƒã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        results_df: è©•ä¾¡çµæœã®DataFrame
    """
    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    required_columns = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'overall_score']
    available_metrics = [col for col in required_columns if col in results_df.columns]
    
    if not available_metrics:
        st.warning("æ¯”è¼ƒå¯èƒ½ãªè©•ä¾¡æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ãŒãªã‘ã‚Œã°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨ˆç®—ã‚’è©¦ã¿ã‚‹
    if 'overlap' not in results_df.columns and 'contexts' in results_df.columns:
        try:
            results_df['overlap'] = results_df['contexts'].apply(
                lambda x: len(' '.join(x).split()) - len(set(' '.join(x).split())) 
                if x and len(x) > 0 else 0
            )
        except Exception as e:
            st.warning(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return
    
    if 'overlap' not in results_df.columns:
        st.warning("ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¯”è¼ƒã«ã¯'overlap'åˆ—ã¾ãŸã¯'contexts'åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return
    
    # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å€¤ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦å¹³å‡ã‚’è¨ˆç®—
    try:
        overlap_scores = results_df.groupby('overlap')[available_metrics].mean().reset_index()
        overlap_scores = overlap_scores.sort_values('overlap')
        
        if len(overlap_scores) <= 1:
            st.warning(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å€¤ãŒ1ç¨®é¡ã—ã‹ã‚ã‚Šã¾ã›ã‚“ï¼ˆå€¤: {results_df['overlap'].iloc[0]}ï¼‰ã€‚æ¯”è¼ƒã«ã¯è¤‡æ•°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—å€¤ãŒå¿…è¦ã§ã™ã€‚")
            return
            
        # å¯è¦–åŒ–
        st.subheader("ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ¯”è¼ƒ")
        
        # ã‚¿ãƒ–ã§è¤‡æ•°ã®å¯è¦–åŒ–ã‚’è¡¨ç¤º
        tab1, tab2 = st.tabs(["æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•", "æ£’ã‚°ãƒ©ãƒ•"])
        
        with tab1:
            fig_line = px.line(
                overlap_scores.melt(id_vars='overlap', var_name='metric', value_name='score'),
                x='overlap',
                y='score',
                color='metric',
                title='ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚ºã”ã¨ã®è©•ä¾¡æŒ‡æ¨™',
                labels={'overlap': 'ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º', 'score': 'ã‚¹ã‚³ã‚¢', 'metric': 'è©•ä¾¡æŒ‡æ¨™'},
                markers=True
            )
            fig_line.update_layout(
                xaxis_title='ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º',
                yaxis_title='ã‚¹ã‚³ã‚¢',
                legend_title='è©•ä¾¡æŒ‡æ¨™',
                height=500,
                hovermode='x unified'
            )
            st.plotly_chart(fig_line, use_container_width=True)
            
        with tab2:
            # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            melted_data = overlap_scores.melt(id_vars='overlap', var_name='metric', value_name='score')
            
            fig_bar = px.bar(
                data_frame=melted_data,
                x='metric',
                y='score',
                color='overlap',
                barmode='group',
                title='è©•ä¾¡æŒ‡æ¨™ã”ã¨ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ¯”è¼ƒ',
                labels={'metric': 'è©•ä¾¡æŒ‡æ¨™', 'score': 'ã‚¹ã‚³ã‚¢', 'overlap': 'ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—'}
            )
            fig_bar.update_layout(
                xaxis_title='è©•ä¾¡æŒ‡æ¨™',
                yaxis_title='ã‚¹ã‚³ã‚¢',
                legend_title='ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º',
                height=500,
                xaxis_tickangle=-45
            )
            st.plotly_chart(fig_bar, use_container_width=True)
            
        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚è¡¨ç¤º
        with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
            st.dataframe(overlap_scores.set_index('overlap').style.background_gradient(cmap='YlGnBu'))
            
    except Exception as e:
        st.error(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ¯”è¼ƒã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.error(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {traceback.format_exc()}")

# --- ã‚°ãƒ©ãƒ•ä¿å­˜ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---

def save_plotly_figure(fig, filename: str, width: int = 1200, height: int = 800, scale: float = 3.0) -> bytes:
    """
    Plotlyã®å›³ã‚’ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜ã™ã‚‹
    
    Args:
        fig: Plotlyã®å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        filename: ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ã¯ä¸è¦ï¼‰
        width: ç”»åƒã®å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
        height: ç”»åƒã®é«˜ã•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
        scale: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆè§£åƒåº¦ã‚’ä¸Šã’ã‚‹å ´åˆï¼‰
        
    Returns:
        bytes: ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆPNGå½¢å¼ï¼‰
    """
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦è¨­å®š
    fig.update_layout(
        font_family=japanese_font,
        title_font_family=japanese_font,
        font=dict(family=f"{japanese_font}, Arial, sans-serif")
    )
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆæ—¥æœ¬èªæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
    temp_dir = tempfile.mkdtemp()
    try:
        temp_file = os.path.join(temp_dir, f"{filename}.png")
        fig.write_image(temp_file, width=width, height=height, scale=scale)
        with open(temp_file, 'rb') as f:
            img_data = f.read()
        return img_data
    except Exception as e:
        st.error(f"ç”»åƒã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def create_zip_with_graphs(bulk_results: Union[dict, list], filename: str = "graphs") -> Optional[bytes]:
    """
    ä¸€æ‹¬è©•ä¾¡çµæœã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã€ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è¿”ã™
    
    Args:
        bulk_results: ä¸€æ‹¬è©•ä¾¡çµæœï¼ˆè¾æ›¸ã¾ãŸã¯ãƒªã‚¹ãƒˆï¼‰
        filename: ç”Ÿæˆã™ã‚‹ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹åï¼ˆæ‹¡å¼µå­ã¯ä¸è¦ï¼‰
        
    Returns:
        Optional[bytes]: ç”Ÿæˆã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã€‚ã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneã‚’è¿”ã™
    """
    # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # é€²æ—çŠ¶æ³ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°
    def update_progress(current: int, total: int, message: str) -> None:
        """é€²æ—çŠ¶æ³ã‚’æ›´æ–°ã™ã‚‹"""
        progress = int((current / total) * 100) if total > 0 else 0
        progress_bar.progress(progress)
        status_text.text(f"é€²æ—: {current}/{total} - {message}")

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    temp_dir = tempfile.mkdtemp()
    saved_files = []
    
    try:
        # çµæœã‚’DataFrameã«å¤‰æ›
        if isinstance(bulk_results, list):
            results_df = pd.DataFrame(bulk_results)
        else:
            results_df = pd.DataFrame([bulk_results])
            
        # å‡¦ç†ã™ã‚‹ã‚°ãƒ©ãƒ•ã®ç·æ•°ã‚’è¨ˆç®—
        total_graphs = 0
        if not results_df.empty:
            # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã¨ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®æ•°
            total_graphs += len(results_df['embedding_model'].unique()) * 2
            # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®æ•°
            if 'chunk_strategy' in results_df.columns:
                total_graphs += len(results_df['chunk_strategy'].unique())
                
        if total_graphs == 0:
            status_text.warning("ç”Ÿæˆã™ã‚‹ã‚°ãƒ©ãƒ•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
            
        current_graph = 0
    
        # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        required_cols = {
            'avg_chunk_len', 'num_chunks', 'overall_score', 'chunk_strategy', 'embedding_model',
            'faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness'
        }
        
        # ä¸è¶³ã‚«ãƒ©ãƒ ã®è£œå®Œ
        for col in required_cols:
            if col not in results_df.columns:
                if col == 'chunk_strategy':
                    results_df[col] = 'unknown'
                else:
                    results_df[col] = 0.5
    
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å®šç¾©
        metrics = ["faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]
        metrics_jp = ["ä¿¡é ¼æ€§", "å›ç­”ã®é–¢é€£æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å†ç¾æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ­£ç¢ºæ€§", "å›ç­”ã®æ­£ç¢ºæ€§"]
        
        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        if 'embedding_model' in results_df.columns:
            model_groups = list(results_df.groupby('embedding_model'))
        else:
            model_groups = [('default', results_df)]
    
        # å„ã‚°ãƒ©ãƒ•ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        
        # 1. ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜
        for model_name, model_data in model_groups:
            if not model_data.empty and 'chunk_size' in model_data.columns and 'overall_score' in model_data.columns:
                # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                fig_bubble = px.scatter(
                    model_data,
                    x="num_chunks",
                    y="avg_chunk_len",
                    size=[min(s * 8, 20) for s in model_data["overall_score"]],  # ãƒãƒ–ãƒ«ã®ã‚µã‚¤ã‚ºã‚’ã•ã‚‰ã«å°ã•ãèª¿æ•´
                    color="overall_score",
                    hover_name=model_data['chunk_strategy'] + '-' + model_data['chunk_size'].astype(str),
                    text=model_data['chunk_strategy'],
                    title=f"{model_name} - ãƒãƒ£ãƒ³ã‚¯åˆ†å¸ƒã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                    labels={
                        "num_chunks": "ãƒãƒ£ãƒ³ã‚¯æ•°",
                        "avg_chunk_len": "å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (æ–‡å­—æ•°)",
                        "overall_score": "ç·åˆã‚¹ã‚³ã‚¢"
                    },
                    color_continuous_scale=px.colors.sequential.Viridis,
                    color_continuous_midpoint=0.5,
                )
                
                # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ›´æ–°
                fig_bubble.update_traces(
                    # ãƒ†ã‚­ã‚¹ãƒˆã¯åˆ¥é€”æ³¨é‡ˆã¨ã—ã¦é…ç½®ã™ã‚‹ãŸã‚ã€ãƒãƒ–ãƒ«å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã¯éè¡¨ç¤ºã«
                    texttemplate='',  # ç©ºã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ãƒ†ã‚­ã‚¹ãƒˆã‚’éè¡¨ç¤ºã«
                    marker=dict(
                        line=dict(width=1.5, color='rgba(0,0,0,0.7)'),
                        opacity=0.8,
                        sizemode='diameter',
                        sizemin=6,  # æœ€å°ã‚µã‚¤ã‚ºã‚’ã•ã‚‰ã«å°ã•ã
                        sizeref=0.1  # ã‚µã‚¤ã‚ºã®æ„Ÿåº¦ã‚’èª¿æ•´
                    ),
                    hovertemplate=
                    '<b>%{hovertext}</b><br><br>' +
                    'ãƒãƒ£ãƒ³ã‚¯æ•°: <b>%{x}</b><br>' +
                    'å¹³å‡ã‚µã‚¤ã‚º: <b>%{y}æ–‡å­—</b><br>' +
                    'ã‚¹ã‚³ã‚¢: <b>%{marker.color:.2f}</b><extra></extra>',
                    hoverlabel=dict(
                        font_size=14,
                        font_family=japanese_font,
                        bgcolor='white',
                        bordercolor='#333',
                        font_color='#333'
                    )
                )
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                fig_bubble.update_layout(
                    title={
                        'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯åˆ†å¸ƒã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                        'x': 0.5,
                        'xanchor': 'center',
                        'font': {
                            'size': 20,
                            'family': japanese_font,
                            'color': '#333'
                        },
                        'y': 0.95,
                        'yanchor': 'top'
                    },
                    coloraxis_colorbar=dict(
                        title=dict(
                            text='ã‚¹ã‚³ã‚¢',
                            font=dict(
                                size=14,
                                family=japanese_font
                            )
                        ),
                        tickfont=dict(
                            family=japanese_font,
                            size=12
                        )
                    ),
                    font=dict(
                        size=14,
                        family=japanese_font,
                        color='#333'
                    ),
                    height=600,
                    margin=dict(l=80, r=50, t=100, b=120),  # ä¸‹éƒ¨ã®ä½™è£•ã‚’å¢—ã‚„ã—ã¦æ³¨é‡ˆç”¨ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    xaxis=dict(
                        title=dict(
                            text='ãƒãƒ£ãƒ³ã‚¯æ•°',
                            font=dict(
                                size=14,
                                family=japanese_font
                            )
                        ),
                        tickfont=dict(
                            size=12,
                            family=japanese_font
                        ),
                        gridcolor='rgba(0,0,0,0.1)',
                        showline=True,
                        linewidth=1,
                        linecolor='#ddd',
                        mirror=True
                    ),
                    yaxis=dict(
                        title=dict(
                            text='å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (æ–‡å­—æ•°)',
                            font=dict(
                                size=14,
                                family=japanese_font
                            )
                        ),
                        tickfont=dict(
                            size=12,
                            family=japanese_font
                        ),
                        gridcolor='rgba(0,0,0,0.1)',
                        showline=True,
                        linewidth=1,
                        linecolor='#ddd',
                        mirror=True
                    )
                )
                
                # ãƒãƒ–ãƒ«ã«æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ–ãƒ«ã®å¤–å´ã«é…ç½®ï¼‰
                for i, row in model_data.iterrows():
                    fig_bubble.add_annotation(
                        x=row['num_chunks'],
                        y=row['avg_chunk_len'],
                        text=row['chunk_strategy'],
                        showarrow=False,
                        yshift=10,  # ãƒãƒ–ãƒ«ã®ä¸Šã«é…ç½®
                        font=dict(
                            size=10,
                            family=japanese_font,
                            color='#333333'
                        ),
                        xanchor='center',
                        yanchor='bottom',
                        opacity=0.9
                    )
                
                # ç”»åƒã¨ã—ã¦ä¿å­˜ï¼ˆé«˜è§£åƒåº¦ã§ï¼‰
                current_graph += 1
                update_progress(current_graph, total_graphs, f"ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­: {model_name}")
                img_data = save_plotly_figure(fig_bubble, f"bubble_chart_{model_name}", width=1200, height=800, scale=3.0)
                if img_data:
                    filepath = os.path.join(temp_dir, f"bubble_chart_{model_name}.png")
                    with open(filepath, 'wb') as f:
                        f.write(img_data)
                    saved_files.append(filepath)
        
        # 2. ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜
        for model_name, model_data in model_groups:
            if not model_data.empty and 'chunk_strategy' in model_data.columns and 'overall_score' in model_data.columns:
                # ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é›†è¨ˆ
                strategy_scores = model_data.groupby('chunk_strategy')['overall_score'].mean().sort_values(ascending=False)
                
                # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                bar_data = pd.DataFrame({
                    'strategy': strategy_scores.index,
                    'score': strategy_scores.values
                })
                
                fig_bar = px.bar(
                    data_frame=bar_data,
                    x='score',
                    y='strategy',
                    orientation='h',
                    title=f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                    labels={'score': 'å¹³å‡ã‚¹ã‚³ã‚¢', 'strategy': 'ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥'},
                    color='score',
                    color_continuous_scale=px.colors.sequential.Viridis,
                )
                
                # ãƒãƒ¼ã®ä¸Šã«ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                fig_bar.update_traces(
                    texttemplate='%{x:.3f}',
                    textposition='outside',
                    hovertemplate='<b>%{y}</b><br>ã‚¹ã‚³ã‚¢: %{x:.3f}<extra></extra>',
                    textfont=dict(size=12, family=japanese_font, color='#333333'),
                )
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                fig_bar.update_layout(
                    title={
                        'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                        'x': 0.5,
                        'xanchor': 'center',
                        'y': 0.95,
                        'yanchor': 'top',
                        'font': {
                            'size': 18,
                            'family': japanese_font,
                            'color': '#333333'
                        }
                    },
                    xaxis=dict(
                        range=[0, 1.1],
                        title=dict(
                            text='å¹³å‡ã‚¹ã‚³ã‚¢',
                            font=dict(
                                size=14,
                                family=japanese_font
                            )
                        ),
                        tickfont=dict(
                            size=12,
                            family=japanese_font
                        ),
                        showgrid=True,
                        gridwidth=1,
                        gridcolor='rgba(0, 0, 0, 0.1)',
                        showline=True,
                        linewidth=1,
                        linecolor='gray',
                        automargin=True
                    ),
                    yaxis=dict(
                        title=dict(
                            text='ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥',
                            font=dict(
                                size=14,
                                family=japanese_font
                            )
                        ),
                        tickfont=dict(
                            size=12,
                            family=japanese_font
                        ),
                        autorange="reversed",
                        automargin=True,
                        showline=True,
                        linewidth=1,
                        linecolor='gray'
                    ),
                    coloraxis_showscale=False,
                    height=500,
                    margin=dict(l=120, r=50, t=120, b=80),  # å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’å¢—ã‚„ã—ã¦ç¸¦è»¸ãƒ©ãƒ™ãƒ«ã®ãŸã‚
                    font=dict(
                        size=14,
                        family=japanese_font,
                        color='#333333'
                    ),
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    hoverlabel=dict(
                        font_size=12,
                        font_family=japanese_font
                    )
                )
                
                # ç”»åƒã¨ã—ã¦ä¿å­˜ï¼ˆé«˜è§£åƒåº¦ã§ï¼‰
                current_graph += 1
                update_progress(current_graph, total_graphs, f"ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­: {model_name}")
                img_data = save_plotly_figure(fig_bar, f"bar_chart_{model_name}", width=1200, height=800, scale=3.0)
                if img_data:
                    filepath = os.path.join(temp_dir, f"bar_chart_{model_name}.png")
                    with open(filepath, 'wb') as f:
                        f.write(img_data)
                    saved_files.append(filepath)
        
        # 3. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜
        if 'chunk_strategy' in results_df.columns:
            chunk_strategies = results_df['chunk_strategy'].unique()
            
            for strategy in chunk_strategies:
                strategy_data = results_df[results_df['chunk_strategy'] == strategy]
                
                if not strategy_data.empty:
                    fig_radar = go.Figure()
                    
                    # å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    for model_name, model_data in model_groups:
                        model_strategy_data = strategy_data[strategy_data['embedding_model'] == model_name] if 'embedding_model' in strategy_data.columns else strategy_data
                        
                        if not model_strategy_data.empty:
                            # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¹³å‡å€¤ã‚’è¨ˆç®—
                            r_values = [model_strategy_data[m].mean() if m in model_strategy_data.columns else 0.5 for m in metrics]
                            
                            # å„ç‚¹ã«è¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™ï¼ˆå€¤ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ï¼‰
                            text_values = [f'{v:.2f}' for v in r_values]
                            
                            # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¿½åŠ 
                            fig_radar.add_trace(go.Scatterpolar(
                                r=r_values,
                                theta=metrics_jp,
                                fill='toself',
                                name=model_name,
                                text=text_values,
                                textposition='top center',
                                textfont=dict(
                                    size=11,
                                    color='black',
                                    family=japanese_font
                                ),
                                hovertemplate='<b>%{theta}</b><br>ã‚¹ã‚³ã‚¢: %{r:.2f}<extra></extra>',
                                line=dict(width=2),
                                mode='lines+markers+text',
                                marker=dict(
                                    size=6,
                                    opacity=0.8
                                )
                            ))
                    
                        # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚’å®šç¾©ï¼ˆè¦–èªæ€§ã®é«˜ã„è‰²ã‚’é¸æŠï¼‰
                    colors = [
                        '#1f77b4',  # é’
                        '#ff7f0e',  # ã‚ªãƒ¬ãƒ³ã‚¸
                        '#2ca02c',  # ç·‘
                        '#d62728',  # èµ¤
                        '#9467bd',  # ç´«
                        '#8c564b',  # èŒ¶è‰²
                        '#e377c2',  # ãƒ”ãƒ³ã‚¯
                        '#7f7f7f',  # ã‚°ãƒ¬ãƒ¼
                        '#bcbd22',  # ã‚ªãƒªãƒ¼ãƒ–
                        '#17becf'   # ã‚·ã‚¢ãƒ³
                    ]
                    
                    # å„ãƒˆãƒ¬ãƒ¼ã‚¹ã«è‰²ã‚’é©ç”¨ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤ºä½ç½®ã‚’èª¿æ•´
                    for i, trace in enumerate(fig_radar.data):
                        # å„ç‚¹ã®è§’åº¦ã«åŸºã¥ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ä½ç½®ã‚’ãšã‚‰ã™
                        text_positions = []
                        for j, theta in enumerate(trace.theta):
                            # è§’åº¦ã«åŸºã¥ã„ã¦ä½ç½®ã‚’èª¿æ•´ï¼ˆ0-360åº¦ã‚’0-11ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
                            angle = (j * 30) % 360  # 30åº¦åˆ»ã¿ã§é…ç½®ï¼ˆ12æ–¹å‘ï¼‰
                            
                            # è§’åº¦ã«å¿œã˜ãŸä½ç½®ã‚’è¨­å®š
                            if 15 <= angle < 165:  # å³å´
                                pos = 'top center'
                            elif 195 <= angle < 345:  # å·¦å´
                                pos = 'bottom center'
                            else:  # ä¸Šä¸‹
                                pos = 'middle right' if angle < 180 else 'middle left'
                                
                            text_positions.append(pos)
                        
                        trace.update(
                            line=dict(
                                width=2.5,
                                color=colors[i % len(colors)]
                            ),
                            marker=dict(
                                size=8,  # ãƒãƒ¼ã‚«ãƒ¼ã‚’å°‘ã—å¤§ãã
                                color=colors[i % len(colors)],
                                line=dict(width=1, color='black'),
                                opacity=0.9
                            ),
                            textposition=text_positions,  # å‹•çš„ã«è¨­å®šã—ãŸä½ç½®ã‚’ä½¿ç”¨
                            textfont=dict(
                                size=10,  # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’å°‘ã—å°ã•ã
                                color='black',
                                family=japanese_font
                            ),
                            mode='lines+markers+text',
                            opacity=0.8
                        )
                    
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                    fig_radar.update_layout(
                        title={
                            'text': f"{strategy} - è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ",
                            'x': 0.5,
                            'xanchor': 'center',
                            'y': 0.95,  # ä¸Šéƒ¨ã«ä½™ç™½ã‚’ç¢ºä¿
                            'yanchor': 'top',
                            'font': {
                                'size': 20,
                                'family': japanese_font,
                                'color': '#333333'
                            }
                        },
                        polar=dict(
                            radialaxis=dict(
                                visible=True,
                                range=[0, 1],
                                tickfont=dict(size=11, family=japanese_font, color='#555555'),
                                tickangle=0,
                                tickformat='.1f',
                                gridwidth=1,
                                gridcolor='lightgray',
                                linecolor='gray',
                                linewidth=1,
                                showline=True
                            ),
                            angularaxis=dict(
                                rotation=90,
                                direction='clockwise',
                                tickfont=dict(size=12, family=japanese_font, color='#333333'),
                                gridwidth=1,
                                gridcolor='lightgray',
                                linecolor='gray',
                                linewidth=1,
                                showline=True
                            ),
                            bgcolor='rgba(250, 250, 250, 0.8)'
                        ),
                        showlegend=True,
                        legend=dict(
                            orientation='h',
                            yanchor='top',
                            y=-0.15,  # ä¸‹å´ã«é…ç½®
                            xanchor='center',
                            x=0.5,
                            font=dict(size=12, family=japanese_font, color='#333333'),
                            bgcolor='rgba(255, 255, 255, 0.8)',
                            bordercolor='#DDDDDD',
                            borderwidth=1,
                            itemclick=False,
                            itemdoubleclick=False
                        ),
                        margin=dict(l=80, r=80, t=120, b=150),  # ä¸‹éƒ¨ã®ä½™ç™½ã‚’å¢—ã‚„ã—ã¦å‡¡ä¾‹ç”¨ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
                        height=600,  # é«˜ã•ã‚’å°‘ã—å¢—ã‚„ã—ã¦ä½™è£•ã‚’æŒãŸã›ã‚‹
                        paper_bgcolor='white',
                        plot_bgcolor='white',
                        font=dict(family=japanese_font, color='#333333'),
                        hoverlabel=dict(
                            font_size=12,
                            font_family=japanese_font
                        )
                    )
                    
                    # ã‚°ãƒªãƒƒãƒ‰ç·šã‚’è¿½åŠ 
                    fig_radar.update_polars(
                        radialaxis=dict(
                            showgrid=True,
                            gridcolor='lightgray',
                            gridwidth=1,
                            showline=True,
                            linecolor='gray',
                            linewidth=1
                        ),
                        angularaxis=dict(
                            showgrid=True,
                            gridcolor='lightgray',
                            gridwidth=1,
                            showline=True,
                            linecolor='gray',
                            linewidth=1
                        )
                    )
                    
                    # ç”»åƒã¨ã—ã¦ä¿å­˜ï¼ˆé«˜è§£åƒåº¦ã§ï¼‰
                    current_graph += 1
                    update_progress(current_graph, total_graphs, f"ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­: {strategy}")
                    img_data = save_plotly_figure(fig_radar, f"radar_chart_{strategy}", width=1200, height=800, scale=3.0)
                    if img_data:
                        filepath = os.path.join(temp_dir, f"radar_chart_{strategy}.png".replace("/", "_"))
                        with open(filepath, 'wb') as f:
                            f.write(img_data)
                        saved_files.append(filepath)
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        if saved_files:
            update_progress(total_graphs, total_graphs, "ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"{filename}_{timestamp}.zip"
            zip_path = os.path.join(temp_dir, zip_filename)
            
            try:
                with zipfile.ZipFile(zip_path, 'w') as zipf:
                    for i, file in enumerate(saved_files, 1):
                        zipf.write(file, os.path.basename(file))
                        update_progress(total_graphs, total_graphs, f"ZIPã«è¿½åŠ ä¸­: {i}/{len(saved_files)}")
                
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¿”ã™
                with open(zip_path, 'rb') as f:
                    zip_data = f.read()
                
                if 'status_text' in locals():
                    status_text.success(f"å®Œäº†ï¼ {len(saved_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                progress_bar.empty()  # å®Œäº†ã—ãŸã‚‰ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ¶ˆã™
                return zip_data
                
            except Exception as e:
                if 'status_text' in locals():
                    status_text.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return None
        else:
            if 'status_text' in locals():
                status_text.warning("ä¿å­˜ã™ã‚‹ã‚°ãƒ©ãƒ•ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
            
    except Exception as e:
        if 'status_text' in locals():
            status_text.error(f"ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None
        
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if 'temp_dir' in locals() and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
            except Exception as e:
                print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

st.set_page_config(layout="wide")
st.title("RAGè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")

# --- Session State Initialization ---
def init_session_state():
    if 'text' not in st.session_state:
        st.session_state.text = ""
    if 'chunks' not in st.session_state:
        st.session_state.chunks = []
    if 'evaluation_results' not in st.session_state:
        st.session_state.evaluation_results = None
    if 'bulk_evaluation_results' not in st.session_state:
        st.session_state.bulk_evaluation_results = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'llm_model' not in st.session_state:
        st.session_state.llm_model = "ollama_llama2" # Default to Ollama
    if 'embedding_model' not in st.session_state:
        st.session_state.embedding_model = "huggingface_bge_small" # Default to HuggingFace

init_session_state()

# --- Backend API Calls ---
# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIã®URLè¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯localhostã‚’æ¨å¥¨ï¼‰ ---
# secrets.tomlãŒå­˜åœ¨ã—ãªãã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã‚ˆã†ä¾‹å¤–å‡¦ç†ã‚’è¿½åŠ 
# Dockerç’°å¢ƒã§ã¯backendã‚µãƒ¼ãƒ“ã‚¹åã§APIã«æ¥ç¶šã™ã‚‹ã®ãŒæ¨å¥¨
import os
try:
    BACKEND_URL = st.secrets.get('BACKEND_URL', os.environ.get('BACKEND_URL', 'http://backend:8000'))  # Dockeræ™‚ã¯backend:8000ã€ãƒ­ãƒ¼ã‚«ãƒ«æ™‚ã¯ç’°å¢ƒå¤‰æ•°orlocalhost
except Exception as e:
    print(f"[WARNING] st.secretsèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    BACKEND_URL = os.environ.get('BACKEND_URL', 'http://backend:8000')


def clear_database():
    try:
        response = requests.post(f"{BACKEND_URL}/clear_db/")
        if response.status_code == 200:
            st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
            # Clear session state related to old data
            st.session_state.text = ""
            st.session_state.chunks = []
            st.session_state.evaluation_results = None
            st.session_state.chat_history = []
        else:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
    except requests.exceptions.RequestException as e:
        st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# --- localStorageãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
def save_state_to_localstorage():
    state_keys = [
        "file_id", "text", "qa_questions", "qa_answers", "uploaded_file_name", "uploaded_file_bytes",
        "evaluation_results", "bulk_evaluation_results", "chunks", "chat_history",
        "current_evaluation", "evaluation_history", "active_tab",
        "tab1_content", "tab2_content", "tab3_content", "tab4_content"
    ]
    state = {}
    for k in state_keys:
        v = st.session_state.get(k)
        if v is not None:
            # ãƒã‚¤ãƒˆåˆ—ã¯base64ã§ä¿å­˜
            if k == "uploaded_file_bytes" and isinstance(v, bytes):
                state[k] = base64.b64encode(v).decode('utf-8')
            # è©•ä¾¡å±¥æ­´ã¨ã‚¿ãƒ–å†…å®¹ã¯JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
            elif k in ["evaluation_history", "bulk_evaluation_results", "tab1_content", "tab2_content", "tab3_content", "tab4_content"]:
                state[k] = json.dumps(v)
            else:
                state[k] = v
    # JSONæ–‡å­—åˆ—ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    js = json.dumps(state, ensure_ascii=False)
    encoded_js = base64.b64encode(js.encode('utf-8')).decode('utf-8')
    components.html(f"""
    <script>
    localStorage.setItem('rag_app_state', '{encoded_js}');
    window.parent.postMessage({{streamlitMessage: 'localStorageSaved'}}, '*');
    </script>
    """, height=0)

# --- session_stateã®åˆæœŸåŒ– ---
def init_session_state():
    default_state = {
        "file_id": None,
        "text": "",
        "qa_questions": [],
        "qa_answers": [],
        "uploaded_file_name": "",
        "uploaded_file_bytes": None,
        "evaluation_results": {},  # è©•ä¾¡çµæœ
        "bulk_evaluation_results": {},  # ãƒãƒ«ã‚¯è©•ä¾¡çµæœ
        "chunks": [],  # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿
        "chat_history": [],  # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        "current_evaluation": None,  # ç¾åœ¨ã®è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³
        "evaluation_history": [],  # è©•ä¾¡å±¥æ­´
        "active_tab": "tab1",  # ç¾åœ¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ãƒ–
        "tab1_content": {"chat_history": []},  # ã‚¿ãƒ–1ã®è¡¨ç¤ºå†…å®¹
        "tab2_content": {},  # ã‚¿ãƒ–2ã®è¡¨ç¤ºå†…å®¹
        "tab3_content": {},  # ã‚¿ãƒ–3ã®è¡¨ç¤ºå†…å®¹
        "tab4_content": {},  # ã‚¿ãƒ–4ã®è¡¨ç¤ºå†…å®¹
        "_localstorage_loaded": False
    }
    for k, v in default_state.items():
        if k not in st.session_state:
            st.session_state[k] = v

# --- UI Layout ---
with st.sidebar:
    # --- ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ ---
    # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    from streamlit_js_eval import streamlit_js_eval
    local_state = streamlit_js_eval(js_expressions="localStorage.getItem('rag_app_state')", key="check_localstorage")
    has_data = local_state is not None or any(
        st.session_state.get(k) not in [None, "", [], {}]
        for k in ["text", "qa_questions", "qa_answers", "uploaded_file_name", "uploaded_file_bytes"]
    )
    
    if has_data:
        if st.button("ãƒªã‚»ãƒƒãƒˆï¼ˆã™ã¹ã¦ã‚¯ãƒªã‚¢ï¼‰"):
            # 1. localStorageã‚’ã‚¯ãƒªã‚¢
            components.html("""
            <script>
            localStorage.removeItem('rag_app_state');
            window.parent.postMessage({streamlitMessage: 'localStorageCleared'}, '*');
            </script>
            """, height=0)
            
            # 2. session_stateã‚’åˆæœŸåŒ–
            init_session_state()
            
            # 3. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢
            try:
                response = requests.post(f"{BACKEND_URL}/clear_db/")
                if response.status_code == 200:
                    st.success("ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
            except requests.exceptions.RequestException as e:
                st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
            
            # 4. ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿
            st.rerun()
    else:
        st.warning("""
        ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“
        
        PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ãƒªã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚
        """)

    # --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒœã‚¿ãƒ³ ---
    if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿åˆæœŸåŒ–"):
        try:
            response = requests.post(f"{BACKEND_URL}/clear_db/")
            if response.status_code == 200:
                st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
                st.session_state.text = ""
                st.session_state.chunks = []
                st.session_state.evaluation_results = None
                st.session_state.chat_history = []
            else:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
        except requests.exceptions.RequestException as e:
            st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

    st.header("è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’APIçµŒç”±ã§å–å¾—
    import requests
    def fetch_models():
        try:
            resp = requests.get(f"{BACKEND_URL}/list_models")
            resp.raise_for_status()
            data = resp.json()
            return data.get("models", [])
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    models = fetch_models()
    model_options = [m['display_name'] for m in models] if models else ["ollama_llama2", "openai"]
    model_names = [m['name'] for m in models] if models else ["ollama_llama2", "openai"]

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠãƒ­ã‚¸ãƒƒã‚¯
    default_idx = 0
    if 'llm_model' in st.session_state and st.session_state.llm_model in model_names:
        default_idx = model_names.index(st.session_state.llm_model)
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã‚’ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        st.warning("è­¦å‘Š: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.sidebar.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        
    llm_model = st.selectbox(
        "LLMãƒ¢ãƒ‡ãƒ«",
        options=model_options,
        index=model_options.index(st.session_state.llm_model) if st.session_state.llm_model in model_options else 0,
        key="llm_model_select"
    )
    
    chat_model_options = ["gpt-4o-mini", "gpt-3.5-turbo", "llama3-70b-8192"]
    chat_model = st.selectbox(
        "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ãƒ‡ãƒ«",
        options=chat_model_options,
        index=0,
        key="chat_model_select"
    )
    
    # Embeddingãƒ¢ãƒ‡ãƒ«ã‚‚åŒæ§˜ã«APIåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯ï¼‰
    embedding_options = {
        "OpenAI": "openai",
        "bge-smallï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é«˜é€Ÿï¼‰": "huggingface_bge_small",
        "MiniLMï¼ˆè»½é‡ãƒ»å¤šè¨€èªï¼‰": "huggingface_miniLM",
    }
    emb_default_idx = 0 if st.session_state.embedding_model == "huggingface_bge_small" else 1
    st.session_state.embedding_model = st.selectbox(
        "Embeddingãƒ¢ãƒ‡ãƒ«",
        embedding_options,
        index=emb_default_idx
    )

    import io
    # --- file_idãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚ã‚Œã°çŠ¶æ…‹ã‚’å¾©å…ƒ ---
    # --- localStorageã‹ã‚‰å¾©å…ƒ ---
    def load_state_from_localstorage():
        from streamlit_js_eval import streamlit_js_eval
        local_state = streamlit_js_eval(js_expressions="localStorage.getItem('rag_app_state')", key="load_localstorage")
        if local_state and not st.session_state.get("_localstorage_loaded", False):
            try:
                # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèª
                if isinstance(local_state, str):
                    local_state = local_state.encode('utf-8')
                # base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦JSONæ–‡å­—åˆ—ã‚’å¾©å…ƒ
                js_bytes = base64.b64decode(local_state)
                js = js_bytes.decode("utf-8")
                state = json.loads(js)
                for k, v in state.items():
                    if k == "uploaded_file_bytes":
                        st.session_state[k] = base64.b64decode(v)
                    elif k in ["evaluation_history", "bulk_evaluation_results", "tab1_content", "tab2_content", "tab3_content", "tab4_content"]:
                        # è©•ä¾¡å±¥æ­´ã¨ã‚¿ãƒ–å†…å®¹ã¯JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãƒ‡ã‚³ãƒ¼ãƒ‰
                        st.session_state[k] = json.loads(v)
                    else:
                        st.session_state[k] = v
                st.session_state["_localstorage_loaded"] = True
            except Exception as e:
                st.warning(f"localStorageå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                init_session_state()    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚session_stateã‚’ã‚¯ãƒªã‚¢
                init_session_state()
        # localStorageå–å¾—æ™‚ã¯window.postMessageã§å€¤ãŒè¿”ã‚‹ãŒã€Streamlitæ¨™æº–ã§ã¯ç›´æ¥å—ã‘å–ã‚Œãªã„ãŸã‚ã€
        # ã“ã“ã§ã¯ã€Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚„å¾©å…ƒã®ãŸã³ã«save_state_to_localstorage()ã€ã‚’å‘¼ã¶ã“ã¨ã§æ°¸ç¶šåŒ–ã™ã‚‹

    load_state_from_localstorage()

    if "file_id" in st.session_state and not st.session_state.get("text"):
        try:
            resp = requests.get(f"{BACKEND_URL}/get_extracted/{st.session_state['file_id']}")
            if resp.status_code == 200:
                data = resp.json()
                st.session_state["text"] = data.get("text", "")
                st.session_state["qa_questions"] = data.get("questions", [])
                st.session_state["qa_answers"] = data.get("answers", [])
                # --- ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒã‚¤ãƒˆåˆ—ã‚‚å¿…ãšå¾©å…ƒ ---
                st.session_state["uploaded_file_name"] = data.get("file_name", f"{st.session_state['file_id']}.pdf")
                if "pdf_bytes_base64" in data:
                    st.session_state["uploaded_file_bytes"] = base64.b64decode(data["pdf_bytes_base64"])
                st.success(f"å‰å›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ID: {st.session_state['file_id']} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
                save_state_to_localstorage()
            else:
                st.warning("ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸã€‚file_idã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚")
                del st.session_state["file_id"]
        except Exception as e:
            st.warning(f"ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒã«å¤±æ•—: {e}")
            del st.session_state["file_id"]
    # ã™ã§ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ã©ã†ã‹ã§UIã‚’åˆ†å²
    if "uploaded_file_bytes" in st.session_state and "uploaded_file_name" in st.session_state:
        st.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆ: {st.session_state['uploaded_file_name']}")
        # å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã„å ´åˆã®ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚„ã‚Šç›´ã™"):
            for key in ["uploaded_file_bytes", "uploaded_file_name", "uploaded_file_size", "text", "qa_questions", "qa_answers", "file_id"]:
                if key in st.session_state:
                    del st.session_state[key]
            components.html("""
            <script>localStorage.removeItem('rag_app_state');</script>
            """, height=0)
            st.rerun()
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’BytesIOã§å¾©å…ƒ
        uploaded_file = io.BytesIO(st.session_state["uploaded_file_bytes"])
        uploaded_file.name = st.session_state["uploaded_file_name"]
        # ã¾ã ãƒ†ã‚­ã‚¹ãƒˆã‚„QAãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ç„¡ã‘ã‚Œã°PDFå‡¦ç†ã‚’å®Ÿè¡Œ
        if not st.session_state.get("text"):
            with st.spinner('PDFã‚’å‡¦ç†ä¸­...'):
                files = {'file': (uploaded_file.name, uploaded_file, 'application/pdf')}
                try:
                    response = requests.post(f"{BACKEND_URL}/uploadfile/", files=files)
                    if response.status_code == 200:
                        data = response.json()
                        if "file_id" in data:
                            st.session_state["file_id"] = data["file_id"]
                        if 'questions' in data and 'answers' in data:
                            st.session_state.text = data['text']
                            st.session_state.qa_questions = data['questions']
                            st.session_state.qa_answers = data['answers']
                            st.success("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ»è³ªå•ãƒ»å›ç­”ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã—ãŸã€‚ä»¥é™ã®è©•ä¾¡å‡¦ç†ã§ã“ã®ã‚»ãƒƒãƒˆãŒä½¿ã‚ã‚Œã¾ã™ã€‚")
                            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
                            for i, q in enumerate(data['questions']):
                                st.write(f"Q{i+1}: {q}")
                            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”:")
                            for i, a in enumerate(data['answers']):
                                st.write(f"A{i+1}: {a}")
                        else:
                            st.error(f"PDFå‡¦ç†APIã®è¿”å´å†…å®¹ã«questions/answersãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {data}")
                        save_state_to_localstorage()
                    else:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {response.text}")
                except requests.exceptions.RequestException as e:
                    st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        else:
            # æ—¢ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ»QAãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºã®ã¿
            st.success("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ»è³ªå•ãƒ»å›ç­”ã‚»ãƒƒãƒˆã¯æ—¢ã«æŠ½å‡ºæ¸ˆã¿ã§ã™ã€‚")
            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
            for i, q in enumerate(st.session_state.qa_questions):
                st.write(f"Q{i+1}: {q}")
            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”:")
            for i, a in enumerate(st.session_state.qa_answers):
                st.write(f"A{i+1}: {a}")
        save_state_to_localstorage()
    else:
        # ã¾ã ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯file_uploaderã‚’è¡¨ç¤º
        uploaded_file = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
        if uploaded_file is not None:
            st.session_state["uploaded_file_bytes"] = uploaded_file.getvalue()
            st.session_state["uploaded_file_name"] = uploaded_file.name
            st.session_state["uploaded_file_size"] = uploaded_file.size
            save_state_to_localstorage()
            st.rerun()

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã‚¿ãƒ–å®šç¾©
tab1, tab2, tab3, tab4, tab_chatbot = st.tabs(["ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š", "è©•ä¾¡", "ä¸€æ‹¬è©•ä¾¡", "æ¯”è¼ƒ", "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"])

# ã‚¿ãƒ–1: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š
with tab1:
    if st.session_state.text:
        st.subheader("ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š")
        chunk_method = st.radio("ãƒãƒ£ãƒ³ã‚¯åŒ–æ–¹å¼", ["recursive", "semantic"], index=0, help="recursive: æ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹, semantic: æ„å‘³ãƒ™ãƒ¼ã‚¹")
        chunk_size = st.slider("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º", 200, 4000, 1000, 100)
        chunk_overlap = st.slider("ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—", 50, 1000, 200, 50)
        embedding_model = st.selectbox("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« (semanticæ™‚å¿…é ˆ)", ["huggingface_bge_small", "openai"], index=0)
        if st.button("ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–"):
            with st.spinner('ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œä¸­...'):
                # 1. Chunk
                payload = {
                    "text": st.session_state.text,
                    "chunk_size": chunk_size,
                    "chunk_overlap": chunk_overlap,
                    "chunk_method": chunk_method,
                }
                if chunk_method == "semantic":
                    payload["embedding_model"] = embedding_model

                chunk_response = requests.post(f"{BACKEND_URL}/chunk/", json=payload)
                if chunk_response.status_code == 200:
                    st.session_state.chunks = chunk_response.json()['chunks']
                    # 2. Embed
                    embed_payload = {"chunks": st.session_state.chunks, "embedding_model": st.session_state.embedding_model}
                    embed_response = requests.post(f"{BACKEND_URL}/embed_and_store/", json=embed_payload)
                    if embed_response.status_code == 200:
                        st.success(f"{len(st.session_state.chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¾ã—ãŸã€‚")
                        # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
                        if not st.session_state.text:
                            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")

# ã‚¿ãƒ–2: è©•ä¾¡
# PDFãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒãƒ£ãƒƒãƒˆç”»é¢ã®ã¿è¡¨ç¤º
if 'uploaded_file_bytes' not in st.session_state:
    st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

with tab2:
    st.header("è©•ä¾¡ã®å®Ÿè¡Œã¨çµæœ")
    
    # è©•ä¾¡å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.expander("è©•ä¾¡ã‚’å®Ÿè¡Œ", expanded=True):
        st.subheader("è©•ä¾¡ã®å®Ÿè¡Œ")
        
        # è³ªå•ã¨å›ç­”ã®å…¥åŠ›
        questions = st.text_area("è©•ä¾¡ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                              value="\n".join(st.session_state.get('qa_questions', [])), 
                              height=150,
                              help="è©•ä¾¡ã—ãŸã„è³ªå•ã‚’1è¡Œãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        answers = st.text_area("å›ç­”ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ã€è³ªå•ã¨é †ç•ªã‚’åˆã‚ã›ã¦ãã ã•ã„ï¼‰", 
                             value="\n".join(st.session_state.get('qa_answers', [])), 
                             height=150,
                             help="è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’1è¡Œãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # è©•ä¾¡å®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_evaluation_tab"):
            questions = [q.strip() for q in questions.split('\n') if q.strip()]
            answers = [a.strip() for a in answers.split('\n') if a.strip()]
            
            if not questions:
                st.warning("è©•ä¾¡ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif len(questions) != len(answers):
                st.warning("è³ªå•ã¨å›ç­”ã®æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
                    try:
                        evaluation_payload = {
                            "questions": questions,
                            "answers": answers,
                            "contexts": ["" for _ in questions],
                            "model": st.session_state.llm_model
                        }
                        
                        response = requests.post(
                            f"{BACKEND_URL}/evaluate/", 
                            json=evaluation_payload
                        )
                        
                        if response.status_code == 200:
                            st.session_state.evaluation_results = response.json()
                            st.session_state.qa_questions = questions
                            st.session_state.qa_answers = answers
                            st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            st.rerun()
                        else:
                            st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {response.text}")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # è©•ä¾¡çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("è©•ä¾¡çµæœ")
    if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
        eval_results = st.session_state.evaluation_results
        
        # è©•ä¾¡çµæœã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
        st.subheader("è©•ä¾¡çµæœã‚µãƒãƒªãƒ¼")
        
        # ã‚¹ã‚³ã‚¢ã®è¡¨ç¤º
        if 'scores' in eval_results:
            scores = eval_results['scores']
            st.write("### ã‚¹ã‚³ã‚¢")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§", f"{scores.get('faithfulness', 0):.2f}")
            with col2:
                st.metric("å›ç­”é–¢é€£æ€§", f"{scores.get('answer_relevancy', 0):.2f}")
            with col3:
                st.metric("æ–‡è„ˆå†ç¾ç‡", f"{scores.get('context_recall', 0):.2f}")
            with col4:
                st.metric("æ–‡è„ˆé©åˆç‡", f"{scores.get('context_precision', 0):.2f}")
        
        # è©³ç´°ãªè©•ä¾¡çµæœã‚’è¡¨ç¤º
        if 'results' in eval_results:
            st.write("### è³ªå•ã”ã¨ã®è©³ç´°")
            for i, result in enumerate(eval_results['results']):
                with st.expander(f"è³ªå• {i+1}: {result.get('question', '')}"):
                    st.write(f"**è³ªå•**: {result.get('question', '')}")
                    st.write(f"**å›ç­”**: {result.get('answer', '')}")
                    st.write(f"**ã‚¹ã‚³ã‚¢**: {result.get('score', 'N/A')}")
                    if 'details' in result:
                        st.json(result['details'])
    else:
        st.info("è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# ä¸€æ‹¬è©•ä¾¡ã‚¿ãƒ–
with tab3:
    st.header("ä¸€æ‹¬è©•ä¾¡")
    st.markdown("Embeddingãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å…¨çµ„ã¿åˆã‚ã›ã§ä¸€æ‹¬è‡ªå‹•è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚")

    # Embeddingãƒ¢ãƒ‡ãƒ«ã®è¤‡æ•°é¸æŠ
    embedding_options = {
        "bge-smallï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é«˜é€Ÿï¼‰": "huggingface_bge_small",
        "MiniLMï¼ˆè»½é‡ãƒ»å¤šè¨€èªï¼‰": "huggingface_miniLM",
        "OpenAI": "openai",
    }
    embedding_labels = list(embedding_options.keys())
    embedding_values = list(embedding_options.values())
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§bge-smallã‚’é¸æŠ
    selected_labels = st.multiselect(
        "Embeddingãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        embedding_labels,
        default=[embedding_labels[0]],
        key="bulk_embeddings_tab3"
    )
    selected_embeddings = [embedding_options[label] for label in selected_labels]

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¤‡æ•°é¸æŠ
    chunk_methods = st.multiselect(
        "ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ã‚’é¸æŠ",
        ["fixed", "recursive", "semantic", "sentence", "paragraph"],
        default=["fixed", "recursive", "semantic"]
    )
    chunk_sizes = st.multiselect(
        "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰",
        [128, 256, 500, 1000, 1500, 2000],
        default=[500, 1000]
    )
    chunk_overlaps = st.multiselect(
        "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆæ–‡å­—æ•°ï¼‰",
        [0, 32, 64, 100, 200, 300],
        default=[0, 100, 200]
    )
    st.caption("â€»Embeddingãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å…¨çµ„ã¿åˆã‚ã›ã§è‡ªå‹•ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã™")

    if st.button("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œ", key="bulk_evaluate_button_2"):
        # ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if not st.session_state.get("text"):
            st.error("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
            
        with st.spinner("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œä¸­..."):
            import concurrent.futures
            from concurrent.futures import ThreadPoolExecutor
            import time
            
            bulk_results = []
            invalid_combinations = []
            valid_combinations = []
            
            # æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›ã®ã¿æŠ½å‡º
            for method in chunk_methods:
                if method in ["fixed", "recursive", "semantic"]:
                    for size in chunk_sizes:
                        for overlap in chunk_overlaps:
                            if size > overlap:
                                valid_combinations.append((method, size, overlap))
                            else:
                                invalid_combinations.append((method, size, overlap))
                else:
                    # size/overlapã‚’ä½¿ã‚ãªã„æ–¹å¼ã¯ä¸€åº¦ã ã‘Noneã§è¿½åŠ 
                    valid_combinations.append((method, None, None))
            
            if not valid_combinations:
                st.error("æœ‰åŠ¹ãªãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚chunk_size > overlap ã¨ãªã‚‹ã‚ˆã†ã«é¸æŠã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            if invalid_combinations:
                st.warning(f"chunk_size <= overlap ã¨ãªã‚‹ä¸æ­£ãªçµ„ã¿åˆã‚ã›ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã—ãŸ: {invalid_combinations}")
            
            # é€²æ—ãƒãƒ¼ã€ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã®è¨­å®š
            progress_bar = st.progress(0)
            progress_text = st.empty()
            status_display = st.empty()
            total_tasks = len(selected_embeddings) * len(valid_combinations)
            
            # å®Œäº†ã‚¿ã‚¹ã‚¯æ•°ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆï¼ˆãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
            completed_tasks = [0]
            
            # è©•ä¾¡ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
            def evaluate_single(emb, method, size, overlap):
                try:
                    # ãƒ†ã‚­ã‚¹ãƒˆã®å­˜åœ¨ã‚’å†ç¢ºèª
                    text = st.session_state.get("text")
                    qa_questions = st.session_state.get("qa_questions", [])
                    qa_answers = st.session_state.get("qa_answers", [])
                    
                    if not text:
                        st.error("è©•ä¾¡å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        return None
                        
                    if not qa_questions or not qa_answers:
                        st.error("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€Q&Aã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                        return None
                        
                    payload = {
                        "embedding_model": emb,
                        "chunk_methods": [method],
                        "chunk_sizes": [size] if size is not None else [1000],
                        "chunk_overlaps": [overlap] if overlap is not None else [200],
                        "text": text,
                        "questions": qa_questions,
                        "answers": qa_answers,
                    }
                    
                    response = requests.post(
                        f"{BACKEND_URL}/bulk_evaluate/", 
                        json=payload, 
                        timeout=300
                    )
                    
                    completed_tasks[0] += 1
                    progress_bar.progress(min(completed_tasks[0] / total_tasks, 1.0))
                    progress_text.text(f"å®Œäº†: {completed_tasks[0]} / {total_tasks} ä»¶")
                    
                    if response.status_code == 200:
                        result = response.json()
                        
                        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãƒªã‚¹ãƒˆã®å ´åˆã¯æœ€åˆã®è¦ç´ ã‚’å–å¾—
                        if isinstance(result, list):
                            if len(result) > 0:
                                result = result[0]
                            else:
                                result = {}
                        
                        # çµæœãŒè¾æ›¸ã§ãªã„å ´åˆã¯è¾æ›¸ã«å¤‰æ›
                        if not isinstance(result, dict):
                            result = {}
                        
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        result['embedding_model'] = emb
                        result['chunk_method'] = method
                        result['chunk_size'] = size
                        result['chunk_overlap'] = overlap
                        
                        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                        if 'overlap' not in result:
                            result['overlap'] = overlap if overlap is not None else 0
                            
                        return result
                    else:
                        st.error("è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°:")
                        st.json({
                            "status_code": response.status_code,
                            "error": response.text,
                            "request_payload": payload
                        })
                        return None
                        
                except requests.exceptions.RequestException as e:
                    st.error(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return None
                except json.JSONDecodeError as e:
                    st.error(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return None
                except Exception as e:
                    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    import traceback
                    st.text(traceback.format_exc())
                    return None
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨: ä¸¦åˆ—å‡¦ç†ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            bulk_results = []
            
            try:
                for emb in selected_embeddings:
                    for method, size, overlap in valid_combinations:
                        # ç¾åœ¨ã®è©•ä¾¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
                        status_display.info(f"è©•ä¾¡ä¸­: {emb}, {method}, size={size}, overlap={overlap}")
                        
                        # è©•ä¾¡ã‚’å®Ÿè¡Œ
                        result = evaluate_single(emb, method, size, overlap)
                        
                        if result:
                            bulk_results.append(result)
                            status_display.success(f"å®Œäº†: {emb}, {method}, size={size}, overlap={overlap}")
                        else:
                            status_display.warning(f"ã‚¹ã‚­ãƒƒãƒ—: {emb}, {method}, size={size}, overlap={overlap}")
                        
                        # å°‘ã—å¾…æ©Ÿï¼ˆUIã®æ›´æ–°ã®ãŸã‚ï¼‰
                        import time
                        time.sleep(0.1)
                
                # æœ€çµ‚çš„ãªé€²æ—è¡¨ç¤º
                progress_text.success(f"å®Œäº†: {total_tasks} / {total_tasks} ä»¶")
                
                # é€²æ—ãƒãƒ¼ã‚’100%ã«
                progress_bar.progress(1.0)
                
                # æœ€çµ‚çš„ãªã‚µãƒãƒªã‚’è¡¨ç¤º
                if bulk_results:
                    status_display.success(f"è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ (æˆåŠŸ: {len(bulk_results)}ä»¶)")
                else:
                    status_display.error("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ‰åŠ¹ãªçµæœã¯å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            except Exception as e:
                status_display.error(f"è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            if bulk_results:
                try:
                    # çµæœãŒãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã®å ´åˆã«ãƒ•ãƒ©ãƒƒãƒˆåŒ–
                    flat_results = []
                    for result in bulk_results:
                        if isinstance(result, list):
                            flat_results.extend(result)
                        else:
                            flat_results.append(result)
                    
                    st.session_state.bulk_evaluation_results = flat_results
                    
                    # çµæœã®è©³ç´°ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
                    if bulk_results:
                        print("\n=== è©•ä¾¡çµæœã‚µãƒãƒª ===")
                        print(f"æˆåŠŸ: {len(bulk_results)}ä»¶")
                        for i, result in enumerate(bulk_results, 1):
                            print(f"\n--- çµæœ {i} ---")
                            print(json.dumps(result, ensure_ascii=False, indent=2))
                except Exception as e:
                    if 'status_text' in locals():
                        status_text.error(f"çµæœã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


    if st.session_state.bulk_evaluation_results:
        st.subheader("ä¸€æ‹¬è©•ä¾¡çµæœ")
        st.write("ä¸€æ‹¬è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.bulk_evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        eval_results = st.session_state.bulk_evaluation_results
        
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ
        if isinstance(eval_results, list):
            results_df = pd.DataFrame(eval_results)
        else:
            results_df = pd.DataFrame([eval_results])
        
        # ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’å±•é–‹
        if 'scores' in results_df.columns:
            # ã‚¹ã‚³ã‚¢ãŒè¾æ›¸å½¢å¼ã§æ ¼ç´ã•ã‚Œã¦ã„ã‚‹å ´åˆã€å„ã‚¹ã‚³ã‚¢ã‚’å€‹åˆ¥ã®ã‚«ãƒ©ãƒ ã«å±•é–‹
            scores_df = pd.json_normalize(results_df['scores'])
            # å…ƒã®ã‚«ãƒ©ãƒ ã¨çµåˆï¼ˆæ¥é ­è¾ã‚’ä»˜ã‘ã¦ç«¶åˆã‚’é¿ã‘ã‚‹ï¼‰
            results_df = pd.concat([results_df.drop('scores', axis=1), scores_df.add_prefix('score_')], axis=1)
        
        # å¿…è¦ã‚«ãƒ©ãƒ è£œå®Œãƒ»ãƒ©ãƒ™ãƒ«åˆ—è¿½åŠ 
        required_cols = {
            'avg_chunk_len', 'num_chunks', 'overall_score', 'chunk_strategy', 'embedding_model',
            'faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness'
        }
        
        # ã‚¹ã‚³ã‚¢ã‚«ãƒ©ãƒ ã®è£œå®Œï¼ˆscore_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒä»˜ã„ã¦ã„ã‚‹å ´åˆã«å¯¾å¿œï¼‰
        for col in ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness', 'overall_score']:
            if f'score_{col}' in results_df.columns and col not in results_df.columns:
                results_df[col] = results_df[f'score_{col}']
        
        missing_cols = required_cols - set(results_df.columns)
        
        if 'chunk_method' in results_df.columns and 'chunk_strategy' not in results_df.columns:
            results_df['chunk_strategy'] = results_df['chunk_method']
            st.info('chunk_strategyåˆ—ã‚’chunk_methodã‹ã‚‰è£œå®Œã—ã¾ã—ãŸ')
        
        if len(results_df) > 0:
            # ä¸è¶³ã‚«ãƒ©ãƒ ã®è£œå®Œ
            if missing_cols:
                st.info(f'ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}ã€‚è‡ªå‹•ã§ä»®å€¤ã‚’è£œå®Œã—ã¾ã™ã€‚')
                for col in missing_cols:
                    if col == 'chunk_strategy':
                        results_df[col] = 'unknown'
                    else:
                        results_df[col] = 0.0
            
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ã‚’è¿½åŠ ï¼ˆchunk_overlapã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦ä½¿ç”¨ï¼‰
            if 'overlap' not in results_df.columns and 'chunk_overlap' in results_df.columns:
                results_df['overlap'] = results_df['chunk_overlap']
            
            # ãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ ï¼ˆchunk_sizeãŒã‚ã‚Œã°å«ã‚ã‚‹ï¼‰
            if 'chunk_size' in results_df.columns:
                results_df['label'] = results_df['chunk_strategy'] + '-' + results_df['chunk_size'].astype(str)
            else:
                results_df['label'] = results_df['chunk_strategy']
        
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ¯”è¼ƒã‚’è¡¨ç¤º
        if 'overlap' in results_df.columns and len(results_df['overlap'].unique()) > 1:
            plot_overlap_comparison(results_df)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å®šç¾©
            metrics = ["faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]
            metrics_jp = ["ä¿¡é ¼æ€§", "å›ç­”ã®é–¢é€£æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å†ç¾æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ­£ç¢ºæ€§", "å›ç­”ã®æ­£ç¢ºæ€§"]
            
            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            if 'embedding_model' in results_df.columns:
                model_groups = list(results_df.groupby('embedding_model'))
            else:
                model_groups = [('default', results_df)]

            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            for model_name, model_data in model_groups:
                if not model_data.empty and 'chunk_size' in model_data.columns and 'overall_score' in model_data.columns:
                    # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                    if 'num_chunks' not in model_data.columns:
                        model_data['num_chunks'] = 0
                    if 'avg_chunk_len' not in model_data.columns:
                        model_data['avg_chunk_len'] = 0
                    if 'overall_score' not in model_data.columns:
                        model_data['overall_score'] = 0
                    
                    # ãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆ0é™¤ç®—ã‚’é˜²ãï¼‰
                    bubble_sizes = [min(s * 20, 50) if pd.notnull(s) else 5 for s in model_data["overall_score"]]
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆå…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ï¼‰
                    plot_data = model_data.copy()
                    plot_data['bubble_size'] = bubble_sizes
                    
                    fig_bubble = px.scatter(
                        data_frame=plot_data,
                        x="num_chunks",
                        y="avg_chunk_len",
                        size="bubble_size",
                        color="overall_score",
                        hover_data={
                            "chunk_size": True,
                            "chunk_strategy": True,
                            "num_chunks": True,
                            "avg_chunk_len": ":.1f",
                            "overall_score": ".3f"
                        },
                        labels={
                            "num_chunks": "ãƒãƒ£ãƒ³ã‚¯æ•°",
                            "avg_chunk_len": "å¹³å‡ãƒãƒ£ãƒ³ã‚¯é•·",
                            "overall_score": "ç·åˆã‚¹ã‚³ã‚¢"
                        },
                        color_continuous_scale=px.colors.sequential.Viridis,
                        width=1200,  # ã‚°ãƒ©ãƒ•ã®å¹…ã‚’æ‹¡å¤§
                        height=800,  # ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’æ‹¡å¤§
                        color_continuous_midpoint=0.5,
                    )
                    
                    # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ›´æ–°
                    fig_bubble.update_traces(
                        textposition='middle center',
                        textfont=dict(size=12, color='white', family='Arial'),
                        marker=dict(line=dict(width=1, color='DarkSlateGrey'), opacity=0.8),
                        hovertemplate=
                        '<b>%{hovertext}</b><br>' +
                        'ãƒãƒ£ãƒ³ã‚¯æ•°: %{x}<br>' +
                        'å¹³å‡ã‚µã‚¤ã‚º: %{y}æ–‡å­—<br>' +
                        'ã‚¹ã‚³ã‚¢: %{marker.color:.2f}<extra></extra>',
                    )
                    
                    fig_bubble.update_layout(
                        title={
                            'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯åˆ†å¸ƒã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                            'x': 0.5,
                            'xanchor': 'center'
                        },
                        coloraxis_colorbar=dict(title="ã‚¹ã‚³ã‚¢"),
                        font=dict(size=14),
                        height=500,
                        margin=dict(l=40, r=40, t=80, b=40)
                    )
                    
                    st.plotly_chart(fig_bubble, use_container_width=True)
                    st.markdown('<br>', unsafe_allow_html=True)
            
            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            for model_name, model_data in model_groups:
                if not model_data.empty and 'chunk_strategy' in model_data.columns and 'overall_score' in model_data.columns:
                    # ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é›†è¨ˆ
                    strategy_scores = model_data.groupby('chunk_strategy')['overall_score'].mean().sort_values(ascending=False)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
                    bar_data = pd.DataFrame({
                        'strategy': strategy_scores.index,
                        'score': strategy_scores.values,
                        'score_text': [f"{x:.3f}" for x in strategy_scores.values]
                    })
                    
                    # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                    fig_bar = px.bar(
                        data_frame=bar_data,
                        x='score',
                        y='strategy',
                        orientation='h',
                        text='score_text',
                        title=f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                        labels={'score': 'å¹³å‡ã‚¹ã‚³ã‚¢', 'strategy': 'ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥'},
                        color='score',
                        color_continuous_scale=px.colors.sequential.Viridis,
                        width=1200,  # ã‚°ãƒ©ãƒ•ã®å¹…ã‚’æ‹¡å¤§
                        height=800,  # ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’æ‹¡å¤§
                    )
                    
                    # ãƒãƒ¼ã®ä¸Šã«ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                    fig_bar.update_traces(
                        texttemplate='%{x:.3f}',
                        textposition='outside',
                        hovertemplate='<b>%{y}</b><br>ã‚¹ã‚³ã‚¢: %{x:.3f}<extra></extra>',
                    )
                    
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                    fig_bar.update_layout(
                        title={
                            'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                            'x': 0.5,
                            'xanchor': 'center',
                            'font': {'size': 18}
                        },
                        xaxis=dict(range=[0, 1.1]),
                        coloraxis_showscale=False,
                        height=400,
                        margin=dict(l=100, r=40, t=100, b=40),
                        yaxis=dict(autorange="reversed"),
                        font=dict(size=14)
                    )
                    
                    # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
                    st.plotly_chart(fig_bar, use_container_width=True)
                    st.markdown('<br>', unsafe_allow_html=True)
            
            # ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã”ã¨ã«ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            if 'chunk_strategy' in results_df.columns:
                chunk_strategies = results_df['chunk_strategy'].unique()
                
                for strategy in chunk_strategies:
                    strategy_data = results_df[results_df['chunk_strategy'] == strategy]
                    
                    if not strategy_data.empty:
                        st.subheader(f"{strategy} - è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ")
                        fig_radar = go.Figure()
                        
                        # å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        for model_name, model_data in model_groups:
                            model_strategy_data = strategy_data[strategy_data['embedding_model'] == model_name] if 'embedding_model' in strategy_data.columns else strategy_data
                            
                            if not model_strategy_data.empty:
                                # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¹³å‡å€¤ã‚’è¨ˆç®—
                                r_values = [model_strategy_data[m].mean() if m in model_strategy_data.columns else 0.5 for m in metrics]
                                
                                fig_radar.add_trace(go.Scatterpolar(
                                    r=r_values,
                                    theta=metrics_jp,
                                    fill='toself',
                                    name=model_name,
                                    hovertemplate='%{theta}: %{r:.2f}<extra></extra>',
                                    line=dict(width=2)
                                ))
                        
                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                        fig_radar.update_layout(
                            polar=dict(
                                radialaxis=dict(
                                    visible=True,
                                    range=[0, 1],
                                    tickfont=dict(size=10),
                                    tickangle=0,
                                    tickformat='.1f',
                                    gridwidth=1
                                ),
                                angularaxis=dict(
                                    rotation=90,
                                    direction='clockwise',
                                    tickfont=dict(size=12),
                                    gridwidth=1
                                ),
                                bgcolor='rgba(0,0,0,0.02)'
                            ),
                            showlegend=True,
                            legend=dict(
                                orientation='h',
                                yanchor='bottom',
                                y=1.15,
                                xanchor='center',
                                x=0.5,
                                font=dict(size=12)
                            ),
                            margin=dict(l=60, r=60, t=30, b=60),  # ä¸Šéƒ¨ãƒãƒ¼ã‚¸ãƒ³ã‚’å°ã•ãèª¿æ•´
                            height=500,
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)'
                        )
                        
                        st.plotly_chart(fig_radar, use_container_width=True)
                        st.markdown('<br>', unsafe_allow_html=True)
            
            # çµæœã‚’DataFrameã«å¤‰æ›
        results_df = pd.DataFrame(st.session_state.bulk_evaluation_results)
        
        # ã‚°ãƒ©ãƒ•ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
        st.markdown("---")
        st.subheader("ã‚°ãƒ©ãƒ•ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
        st.markdown("""
        <style>
            .stDownloadButton button {
                width: 100%;
                height: 3em;
                font-size: 1.2em !important;
                background-color: #4CAF50;
                color: white;
                border: none;
                border-radius: 5px;
                cursor: pointer;
                transition: background-color 0.3s;
            }
            .stDownloadButton button:hover {
                background-color: #45a049;
            }
            .stDownloadButton button:active {
                background-color: #3e8e41;
            }
        </style>
        """, unsafe_allow_html=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        if st.button("ğŸ“¥ ã™ã¹ã¦ã®ã‚°ãƒ©ãƒ•ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="download_all_graphs"):
            with st.spinner("ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã¦ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                zip_data = create_zip_with_graphs(st.session_state.bulk_evaluation_results, "rag_evaluation_graphs")
                
                if zip_data:
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ
                    b64 = base64.b64encode(zip_data).decode()
                    href = f'<a href="data:application/zip;base64,{b64}" download="rag_evaluation_graphs.zip" class="download-link">ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
                    st.markdown(href, unsafe_allow_html=True)
                    st.success("ã‚°ãƒ©ãƒ•ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.error("ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

with tab4:
    if 'uploaded_file_bytes' not in st.session_state:
        st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    st.header("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
    
    if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
        st.subheader("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
        
        # è©•ä¾¡çµæœã‚’DataFrameã«å¤‰æ›
        eval_results = st.session_state.evaluation_results
        if 'results' in eval_results:
            df_data = []
            for i, result in enumerate(eval_results['results']):
                row = {
                    'è³ªå•ç•ªå·': i+1,
                    'è³ªå•': result.get('question', ''),
                    'å›ç­”': result.get('answer', '')
                }
                if 'details' in result:
                    for k, v in result['details'].items():
                        if isinstance(v, (int, float)):
                            row[k] = v
                df_data.append(row)
            
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(df)
                
                # ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–
                score_cols = [col for col in df.columns if col not in ['è³ªå•ç•ªå·', 'è³ªå•', 'å›ç­”']]
                if score_cols:
                    st.subheader("ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ")
                    fig = px.bar(df, x='è³ªå•ç•ªå·', y=score_cols, 
                                title="è³ªå•ã”ã¨ã®ã‚¹ã‚³ã‚¢æ¯”è¼ƒ",
                                labels={'value': 'ã‚¹ã‚³ã‚¢', 'variable': 'è©•ä¾¡é …ç›®', 'è³ªå•ç•ªå·': 'è³ªå•ç•ªå·'})
                    st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("æ¯”è¼ƒã™ã‚‹è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡ã¾ãŸã¯ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        # --- è‡ªå‹•ç”ŸæˆQAã‚»ãƒƒãƒˆå„ªå…ˆã§åˆ©ç”¨ ---
        auto_questions = st.session_state.get('qa_questions', None)
        auto_answers = st.session_state.get('qa_answers', None)
        if auto_questions:
            st.markdown("#### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¾ã™")
            questions = auto_questions
            st.write("\n".join([f"Q{i+1}: {q}" for i, q in enumerate(questions)]))
        else:
            questions_input = st.text_area("1è¡Œã«1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150, 
                                           value="ä¸»ãªãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æŠ€è¡“ã«ã¯ä½•ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨å†å¸°çš„æ–‡å­—åˆ†å‰²ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ")
            questions = [q.strip() for q in questions_input.split('\n') if q.strip()]

        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_evaluation"):
            if not questions:
                st.warning("æœ€ä½1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"):
                    try:
                        # 1. è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                        answers = []
                        contexts = []
                        # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Œã°åˆ©ç”¨ ---
                        if auto_answers and len(auto_answers) == len(questions):
                            answers = auto_answers
                            st.success("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                        else:
                            # å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¿½åŠ 
                            st.warning("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            st.stop()

                        # 2. è©•ä¾¡ã‚’å®Ÿè¡Œ
                        evaluation_payload = {
                            "questions": questions,
                            "answers": answers,
                            "contexts": ["" for _ in questions],  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ç©ºã§ä»®è¨­å®š
                            "model": st.session_state.llm_model
                        }
                        
                        eval_response = requests.post(f"{BACKEND_URL}/evaluate/", json=evaluation_payload)
                        if eval_response.status_code == 200:
                            st.session_state.evaluation_results = eval_response.json()
                            st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            # è©•ä¾¡çµæœã‚’è¡¨ç¤ºã™ã‚‹ã‚¿ãƒ–ã«ç§»å‹•
                            st.session_state.active_tab = "è©•ä¾¡"
                            st.rerun()
                        else:
                            st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {eval_response.text}")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.warning(f"chunk_size <= overlap ã¨ãªã‚‹ä¸æ­£ãªçµ„ã¿åˆã‚ã›ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã—ãŸ: ({embedding}, {strategy}, {size}, {overlap})")
                    # é€²æ—ãƒãƒ¼ã®è¨­å®š
                    progress_bar = st.progress(0)
                    total_tasks = len(futures)
                    completed_tasks = 0
                    for future in concurrent.futures.as_completed(futures):
                        result = future.result()
                        if result is not None:
                            answers.append(result['answer'])
                            contexts.append(result['context'])
                        completed_tasks += 1
                        progress_bar.progress(min(completed_tasks / total_tasks, 1.0))
                    progress_bar.empty()
                    st.session_state.evaluation_results = {"answers": answers, "contexts": contexts}
                    st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        if st.session_state.evaluation_results:
            st.subheader("è©•ä¾¡æŒ‡æ¨™")
            st.write("è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
            # evaluation_resultsãŒãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆã«å¯¾å¿œ
            eval_results = st.session_state.evaluation_results
            if isinstance(eval_results, list):
                results_df = pd.DataFrame(eval_results)
            else:
                results_df = pd.DataFrame([eval_results])
            # è‹±èªâ†’æ—¥æœ¬èªã®æŒ‡æ¨™åãƒãƒƒãƒ”ãƒ³ã‚°
            METRIC_JA = {
                "faithfulness": "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§",
                "answer_relevancy": "å›ç­”é–¢é€£æ€§",
                "context_recall": "æ–‡è„ˆå†ç¾ç‡",
                "context_precision": "æ–‡è„ˆé©åˆç‡"
            }

            # DataFrameã®ã‚«ãƒ©ãƒ åã‚‚æ—¥æœ¬èªã«å¤‰æ›ã—ã¦è¡¨ç¤º
            results_df_ja = results_df.rename(columns=METRIC_JA)
            st.dataframe(results_df_ja)

            # Plotting
            metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
            available_metrics = [m for m in metrics if m in results_df.columns]

            if available_metrics:
                plot_df = results_df[available_metrics].T.reset_index()
                plot_df['index'] = plot_df['index'].map(METRIC_JA)
                plot_df.columns = ['æŒ‡æ¨™', 'ã‚¹ã‚³ã‚¢']

                # Performance Rankingé¢¨ æ¨ªæ£’ã‚°ãƒ©ãƒ•
                fig_bar = px.bar(
                    plot_df,
                    y='æŒ‡æ¨™',
                    x='ã‚¹ã‚³ã‚¢',
                    orientation='h',
                    text='ã‚¹ã‚³ã‚¢',
                    title="Performance Ranking",
                    labels={"æŒ‡æ¨™": "Metric", "ã‚¹ã‚³ã‚¢": "Score"},
                )
                fig_bar.update_traces(texttemplate='%{x:.3f}', textposition='outside')
                fig_bar.update_layout(
                    title={
                        'text': "RAG Strategy Performance Ranking<br><sup>Error bars show standard deviation â€¢ * indicates statistical significance</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    font=dict(size=16),
                    height=550,
                    margin=dict(l=40, r=40, t=80, b=40),
                    showlegend=False
                )
                st.plotly_chart(fig_bar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_bar:
                    st.session_state['eval_figs'].append(fig_bar)
                st.markdown('<br>', unsafe_allow_html=True)

                # RAGAS Metrics Comparisoné¢¨ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
                import plotly.graph_objects as go
                metrics_en = ['Faithfulness', 'Answer Relevancy', 'Context Recall', 'Context Precision']
                metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
                r_values = [results_df[m].iloc[0] if m in results_df.columns else 0 for m in metrics]
                fig_radar = go.Figure()
                fig_radar.add_trace(go.Scatterpolar(
                    r=r_values,
                    theta=metrics_en,
                    fill='toself',
                    name='Sample'
                ))
                fig_radar.update_layout(
                    title={
                        'text': "RAGAS Metrics Comparison<br><sup>All metrics normalized to 0-1 scale</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    showlegend=True,
                    font=dict(size=16),
                    height=600,
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                st.plotly_chart(fig_radar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_radar:
                    st.session_state['eval_figs'].append(fig_radar)
                st.markdown('<br>', unsafe_allow_html=True)
            else:
                st.warning("è©•ä¾¡æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡APIã®è¿”å´å†…å®¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¿ãƒ–
with tab_chatbot:
    st.header("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ã‚’ç”Ÿæˆ
        response_text = ""
        with st.chat_message("assistant"):
            try:
                if not os.getenv("OPENAI_API_KEY"):
                    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    response_text = "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™
                messages = [{"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}]
                messages.extend([{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_messages])
                
                # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦APIã‚’å‘¼ã³å‡ºã—
                if st.session_state.chat_model in ["gpt-4o-mini", "gpt-3.5-turbo"]:
                    # OpenAI APIã‚’ä½¿ç”¨
                    api_key = os.getenv("OPENAI_API_KEY")
                    if not api_key:
                        response_text = "ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                    else:
                        try:
                            client = OpenAI(api_key=api_key)
                            response = client.chat.completions.create(
                                model=st.session_state.chat_model,
                                messages=messages,
                                temperature=0.7,
                                max_tokens=1000
                            )
                            response_text = response.choices[0].message.content
                        except Exception as e:
                            response_text = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                else:
                    # ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼ˆä¾‹ã¨ã—ã¦ã®å®Ÿè£…ï¼‰
                    response_text = f"{st.session_state.chat_model} ã‹ã‚‰ã®å¿œç­”: ã‚ãªãŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€Œ{prompt}ã€ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n\nï¼ˆæ³¨: ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼å¿œç­”ã§ã™ï¼‰"
                
                st.markdown(response_text)
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.chat_messages.append({"role": "assistant", "content": response_text})
                
            except Exception as e:
                error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_msg)
                st.session_state.chat_messages.append({"role": "assistant", "content": error_msg})
        
        # ç”»é¢ã‚’æ›´æ–°
        st.rerun()