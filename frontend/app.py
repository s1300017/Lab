from datetime import datetime
from pytz import timezone

def jst_now_str():
    return datetime.now(timezone('Asia/Tokyo')).strftime('%Y-%m-%d %H:%M:%S JST')

import os
import json
import streamlit as st
import streamlit.components.v1 as components
import base64
import json
import pandas as pd
import plotly.express as px
import requests
from typing import List, Dict, Any, Optional, Tuple, Literal
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import plotly.graph_objects as go  # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç­‰ã§ä½¿ç”¨
from openai import OpenAI
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

st.set_page_config(layout="wide")
st.title("RAGè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")

# --- Session State Initialization ---
def init_session_state():
    if 'text' not in st.session_state:
        st.session_state.text = ""
    if 'chunks' not in st.session_state:
        st.session_state.chunks = []
    if 'evaluation_results' not in st.session_state:
        st.session_state.evaluation_results = None
    if 'bulk_evaluation_results' not in st.session_state:
        st.session_state.bulk_evaluation_results = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'llm_model' not in st.session_state:
        st.session_state.llm_model = "ollama_llama2" # Default to Ollama
    if 'embedding_model' not in st.session_state:
        st.session_state.embedding_model = "huggingface_bge_small" # Default to HuggingFace

init_session_state()

# --- Backend API Calls ---
# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIã®URLè¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯localhostã‚’æ¨å¥¨ï¼‰ ---
# secrets.tomlãŒå­˜åœ¨ã—ãªãã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã‚ˆã†ä¾‹å¤–å‡¦ç†ã‚’è¿½åŠ 
# Dockerç’°å¢ƒã§ã¯backendã‚µãƒ¼ãƒ“ã‚¹åã§APIã«æ¥ç¶šã™ã‚‹ã®ãŒæ¨å¥¨
import os
try:
    BACKEND_URL = st.secrets.get('BACKEND_URL', os.environ.get('BACKEND_URL', 'http://backend:8000'))  # Dockeræ™‚ã¯backend:8000ã€ãƒ­ãƒ¼ã‚«ãƒ«æ™‚ã¯ç’°å¢ƒå¤‰æ•°orlocalhost
except Exception as e:
    print(f"[WARNING] st.secretsèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    BACKEND_URL = os.environ.get('BACKEND_URL', 'http://backend:8000')


def clear_database():
    try:
        response = requests.post(f"{BACKEND_URL}/clear_db/")
        if response.status_code == 200:
            st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
            # Clear session state related to old data
            st.session_state.text = ""
            st.session_state.chunks = []
            st.session_state.evaluation_results = None
            st.session_state.chat_history = []
        else:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
    except requests.exceptions.RequestException as e:
        st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# --- localStorageãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
def save_state_to_localstorage():
    state_keys = [
        "file_id", "text", "qa_questions", "qa_answers", "uploaded_file_name", "uploaded_file_bytes",
        "evaluation_results", "bulk_evaluation_results", "chunks", "chat_history",
        "current_evaluation", "evaluation_history", "active_tab",
        "tab1_content", "tab2_content", "tab3_content", "tab4_content"
    ]
    state = {}
    for k in state_keys:
        v = st.session_state.get(k)
        if v is not None:
            # ãƒã‚¤ãƒˆåˆ—ã¯base64ã§ä¿å­˜
            if k == "uploaded_file_bytes" and isinstance(v, bytes):
                state[k] = base64.b64encode(v).decode('utf-8')
            # è©•ä¾¡å±¥æ­´ã¨ã‚¿ãƒ–å†…å®¹ã¯JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
            elif k in ["evaluation_history", "bulk_evaluation_results", "tab1_content", "tab2_content", "tab3_content", "tab4_content"]:
                state[k] = json.dumps(v)
            else:
                state[k] = v
    # JSONæ–‡å­—åˆ—ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    js = json.dumps(state, ensure_ascii=False)
    encoded_js = base64.b64encode(js.encode('utf-8')).decode('utf-8')
    components.html(f"""
    <script>
    localStorage.setItem('rag_app_state', '{encoded_js}');
    window.parent.postMessage({{streamlitMessage: 'localStorageSaved'}}, '*');
    </script>
    """, height=0)

# --- session_stateã®åˆæœŸåŒ– ---
def init_session_state():
    default_state = {
        "file_id": None,
        "text": "",
        "qa_questions": [],
        "qa_answers": [],
        "uploaded_file_name": "",
        "uploaded_file_bytes": None,
        "evaluation_results": {},  # è©•ä¾¡çµæœ
        "bulk_evaluation_results": {},  # ãƒãƒ«ã‚¯è©•ä¾¡çµæœ
        "chunks": [],  # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿
        "chat_history": [],  # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        "current_evaluation": None,  # ç¾åœ¨ã®è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³
        "evaluation_history": [],  # è©•ä¾¡å±¥æ­´
        "active_tab": "tab1",  # ç¾åœ¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ãƒ–
        "tab1_content": {"chat_history": []},  # ã‚¿ãƒ–1ã®è¡¨ç¤ºå†…å®¹
        "tab2_content": {},  # ã‚¿ãƒ–2ã®è¡¨ç¤ºå†…å®¹
        "tab3_content": {},  # ã‚¿ãƒ–3ã®è¡¨ç¤ºå†…å®¹
        "tab4_content": {},  # ã‚¿ãƒ–4ã®è¡¨ç¤ºå†…å®¹
        "_localstorage_loaded": False
    }
    for k, v in default_state.items():
        if k not in st.session_state:
            st.session_state[k] = v

# --- UI Layout ---
with st.sidebar:
    # --- ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ ---
    # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    from streamlit_js_eval import streamlit_js_eval
    local_state = streamlit_js_eval(js_expressions="localStorage.getItem('rag_app_state')", key="check_localstorage")
    has_data = local_state is not None or any(
        st.session_state.get(k) not in [None, "", [], {}]
        for k in ["text", "qa_questions", "qa_answers", "uploaded_file_name", "uploaded_file_bytes"]
    )
    
    if has_data:
        if st.button("ãƒªã‚»ãƒƒãƒˆï¼ˆã™ã¹ã¦ã‚¯ãƒªã‚¢ï¼‰"):
            # 1. localStorageã‚’ã‚¯ãƒªã‚¢
            components.html("""
            <script>
            localStorage.removeItem('rag_app_state');
            window.parent.postMessage({streamlitMessage: 'localStorageCleared'}, '*');
            </script>
            """, height=0)
            
            # 2. session_stateã‚’åˆæœŸåŒ–
            init_session_state()
            
            # 3. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢
            try:
                response = requests.post(f"{BACKEND_URL}/clear_db/")
                if response.status_code == 200:
                    st.success("ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
            except requests.exceptions.RequestException as e:
                st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
            
            # 4. ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿
            st.rerun()
    else:
        st.warning("""
        ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“
        
        PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ãƒªã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚
        """)

    # --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒœã‚¿ãƒ³ ---
    if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿åˆæœŸåŒ–"):
        try:
            response = requests.post(f"{BACKEND_URL}/clear_db/")
            if response.status_code == 200:
                st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ­£å¸¸ã«ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")
                st.session_state.text = ""
                st.session_state.chunks = []
                st.session_state.evaluation_results = None
                st.session_state.chat_history = []
            else:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
        except requests.exceptions.RequestException as e:
            st.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

    st.header("è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’APIçµŒç”±ã§å–å¾—
    import requests
    def fetch_models():
        try:
            resp = requests.get(f"{BACKEND_URL}/list_models")
            resp.raise_for_status()
            data = resp.json()
            return data.get("models", [])
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    models = fetch_models()
    model_options = [m['display_name'] for m in models] if models else ["ollama_llama2", "openai"]
    model_names = [m['name'] for m in models] if models else ["ollama_llama2", "openai"]

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠãƒ­ã‚¸ãƒƒã‚¯
    default_idx = 0
    if 'llm_model' in st.session_state and st.session_state.llm_model in model_names:
        default_idx = model_names.index(st.session_state.llm_model)
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã‚’ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        st.warning("è­¦å‘Š: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.sidebar.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        
    llm_model = st.selectbox(
        "LLMãƒ¢ãƒ‡ãƒ«",
        options=model_options,
        index=model_options.index(st.session_state.llm_model) if st.session_state.llm_model in model_options else 0,
        key="llm_model_select"
    )
    
    chat_model_options = ["gpt-4o-mini", "gpt-3.5-turbo", "llama3-70b-8192"]
    chat_model = st.selectbox(
        "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ãƒ‡ãƒ«",
        options=chat_model_options,
        index=0,
        key="chat_model_select"
    )
    
    # Embeddingãƒ¢ãƒ‡ãƒ«ã‚‚åŒæ§˜ã«APIåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯ï¼‰
    embedding_options = {
        "OpenAI": "openai",
        "bge-smallï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é«˜é€Ÿï¼‰": "huggingface_bge_small",
        "MiniLMï¼ˆè»½é‡ãƒ»å¤šè¨€èªï¼‰": "huggingface_miniLM",
    }
    emb_default_idx = 0 if st.session_state.embedding_model == "huggingface_bge_small" else 1
    st.session_state.embedding_model = st.selectbox(
        "Embeddingãƒ¢ãƒ‡ãƒ«",
        embedding_options,
        index=emb_default_idx
    )

    import io
    # --- file_idãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚ã‚Œã°çŠ¶æ…‹ã‚’å¾©å…ƒ ---
    # --- localStorageã‹ã‚‰å¾©å…ƒ ---
    def load_state_from_localstorage():
        from streamlit_js_eval import streamlit_js_eval
        local_state = streamlit_js_eval(js_expressions="localStorage.getItem('rag_app_state')", key="load_localstorage")
        if local_state and not st.session_state.get("_localstorage_loaded", False):
            try:
                # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèª
                if isinstance(local_state, str):
                    local_state = local_state.encode('utf-8')
                # base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦JSONæ–‡å­—åˆ—ã‚’å¾©å…ƒ
                js_bytes = base64.b64decode(local_state)
                js = js_bytes.decode("utf-8")
                state = json.loads(js)
                for k, v in state.items():
                    if k == "uploaded_file_bytes":
                        st.session_state[k] = base64.b64decode(v)
                    elif k in ["evaluation_history", "bulk_evaluation_results", "tab1_content", "tab2_content", "tab3_content", "tab4_content"]:
                        # è©•ä¾¡å±¥æ­´ã¨ã‚¿ãƒ–å†…å®¹ã¯JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãƒ‡ã‚³ãƒ¼ãƒ‰
                        st.session_state[k] = json.loads(v)
                    else:
                        st.session_state[k] = v
                st.session_state["_localstorage_loaded"] = True
            except Exception as e:
                st.warning(f"localStorageå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                init_session_state()    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚session_stateã‚’ã‚¯ãƒªã‚¢
                init_session_state()
        # localStorageå–å¾—æ™‚ã¯window.postMessageã§å€¤ãŒè¿”ã‚‹ãŒã€Streamlitæ¨™æº–ã§ã¯ç›´æ¥å—ã‘å–ã‚Œãªã„ãŸã‚ã€
        # ã“ã“ã§ã¯ã€Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚„å¾©å…ƒã®ãŸã³ã«save_state_to_localstorage()ã€ã‚’å‘¼ã¶ã“ã¨ã§æ°¸ç¶šåŒ–ã™ã‚‹

    load_state_from_localstorage()

    if "file_id" in st.session_state and not st.session_state.get("text"):
        try:
            resp = requests.get(f"{BACKEND_URL}/get_extracted/{st.session_state['file_id']}")
            if resp.status_code == 200:
                data = resp.json()
                st.session_state["text"] = data.get("text", "")
                st.session_state["qa_questions"] = data.get("questions", [])
                st.session_state["qa_answers"] = data.get("answers", [])
                # --- ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒã‚¤ãƒˆåˆ—ã‚‚å¿…ãšå¾©å…ƒ ---
                st.session_state["uploaded_file_name"] = data.get("file_name", f"{st.session_state['file_id']}.pdf")
                if "pdf_bytes_base64" in data:
                    st.session_state["uploaded_file_bytes"] = base64.b64decode(data["pdf_bytes_base64"])
                st.success(f"å‰å›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ID: {st.session_state['file_id']} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
                save_state_to_localstorage()
            else:
                st.warning("ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸã€‚file_idã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚")
                del st.session_state["file_id"]
        except Exception as e:
            st.warning(f"ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒã«å¤±æ•—: {e}")
            del st.session_state["file_id"]
    # ã™ã§ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ã©ã†ã‹ã§UIã‚’åˆ†å²
    if "uploaded_file_bytes" in st.session_state and "uploaded_file_name" in st.session_state:
        st.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆ: {st.session_state['uploaded_file_name']}")
        # å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã„å ´åˆã®ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚„ã‚Šç›´ã™"):
            for key in ["uploaded_file_bytes", "uploaded_file_name", "uploaded_file_size", "text", "qa_questions", "qa_answers", "file_id"]:
                if key in st.session_state:
                    del st.session_state[key]
            components.html("""
            <script>localStorage.removeItem('rag_app_state');</script>
            """, height=0)
            st.rerun()
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’BytesIOã§å¾©å…ƒ
        uploaded_file = io.BytesIO(st.session_state["uploaded_file_bytes"])
        uploaded_file.name = st.session_state["uploaded_file_name"]
        # ã¾ã ãƒ†ã‚­ã‚¹ãƒˆã‚„QAãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ç„¡ã‘ã‚Œã°PDFå‡¦ç†ã‚’å®Ÿè¡Œ
        if not st.session_state.get("text"):
            with st.spinner('PDFã‚’å‡¦ç†ä¸­...'):
                files = {'file': (uploaded_file.name, uploaded_file, 'application/pdf')}
                try:
                    response = requests.post(f"{BACKEND_URL}/uploadfile/", files=files)
                    if response.status_code == 200:
                        data = response.json()
                        if "file_id" in data:
                            st.session_state["file_id"] = data["file_id"]
                        if 'questions' in data and 'answers' in data:
                            st.session_state.text = data['text']
                            st.session_state.qa_questions = data['questions']
                            st.session_state.qa_answers = data['answers']
                            st.success("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ»è³ªå•ãƒ»å›ç­”ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã—ãŸã€‚ä»¥é™ã®è©•ä¾¡å‡¦ç†ã§ã“ã®ã‚»ãƒƒãƒˆãŒä½¿ã‚ã‚Œã¾ã™ã€‚")
                            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
                            for i, q in enumerate(data['questions']):
                                st.write(f"Q{i+1}: {q}")
                            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”:")
                            for i, a in enumerate(data['answers']):
                                st.write(f"A{i+1}: {a}")
                        else:
                            st.error(f"PDFå‡¦ç†APIã®è¿”å´å†…å®¹ã«questions/answersãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {data}")
                        save_state_to_localstorage()
                    else:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {response.text}")
                except requests.exceptions.RequestException as e:
                    st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        else:
            # æ—¢ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ»QAãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºã®ã¿
            st.success("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ»è³ªå•ãƒ»å›ç­”ã‚»ãƒƒãƒˆã¯æ—¢ã«æŠ½å‡ºæ¸ˆã¿ã§ã™ã€‚")
            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
            for i, q in enumerate(st.session_state.qa_questions):
                st.write(f"Q{i+1}: {q}")
            st.write("### è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”:")
            for i, a in enumerate(st.session_state.qa_answers):
                st.write(f"A{i+1}: {a}")
        save_state_to_localstorage()
    else:
        # ã¾ã ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯file_uploaderã‚’è¡¨ç¤º
        uploaded_file = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
        if uploaded_file is not None:
            st.session_state["uploaded_file_bytes"] = uploaded_file.getvalue()
            st.session_state["uploaded_file_name"] = uploaded_file.name
            st.session_state["uploaded_file_size"] = uploaded_file.size
            save_state_to_localstorage()
            st.rerun()

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã‚¿ãƒ–å®šç¾©
tab1, tab2, tab3, tab4, tab_chatbot = st.tabs(["ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š", "è©•ä¾¡", "ä¸€æ‹¬è©•ä¾¡", "æ¯”è¼ƒ", "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"])

# ã‚¿ãƒ–1: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š
with tab1:
    if st.session_state.text:
        st.subheader("ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š")
        chunk_method = st.radio("ãƒãƒ£ãƒ³ã‚¯åŒ–æ–¹å¼", ["recursive", "semantic"], index=0, help="recursive: æ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹, semantic: æ„å‘³ãƒ™ãƒ¼ã‚¹")
        chunk_size = st.slider("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º", 200, 4000, 1000, 100)
        chunk_overlap = st.slider("ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—", 50, 1000, 200, 50)
        embedding_model = st.selectbox("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« (semanticæ™‚å¿…é ˆ)", ["huggingface_bge_small", "openai"], index=0)
        if st.button("ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–"):
            with st.spinner('ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œä¸­...'):
                # 1. Chunk
                payload = {
                    "text": st.session_state.text,
                    "chunk_size": chunk_size,
                    "chunk_overlap": chunk_overlap,
                    "chunk_method": chunk_method,
                }
                if chunk_method == "semantic":
                    payload["embedding_model"] = embedding_model

                chunk_response = requests.post(f"{BACKEND_URL}/chunk/", json=payload)
                if chunk_response.status_code == 200:
                    st.session_state.chunks = chunk_response.json()['chunks']
                    # 2. Embed
                    embed_payload = {"chunks": st.session_state.chunks, "embedding_model": st.session_state.embedding_model}
                    embed_response = requests.post(f"{BACKEND_URL}/embed_and_store/", json=embed_payload)
                    if embed_response.status_code == 200:
                        st.success(f"{len(st.session_state.chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¾ã—ãŸã€‚")
                        # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
                        if not st.session_state.text:
                            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")

# ã‚¿ãƒ–2: è©•ä¾¡
# PDFãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒãƒ£ãƒƒãƒˆç”»é¢ã®ã¿è¡¨ç¤º
if 'uploaded_file_bytes' not in st.session_state:
    st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

with tab2:
    st.header("è©•ä¾¡ã®å®Ÿè¡Œã¨çµæœ")
    
    # è©•ä¾¡å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.expander("è©•ä¾¡ã‚’å®Ÿè¡Œ", expanded=True):
        st.subheader("è©•ä¾¡ã®å®Ÿè¡Œ")
        
        # è³ªå•ã¨å›ç­”ã®å…¥åŠ›
        questions = st.text_area("è©•ä¾¡ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                              value="\n".join(st.session_state.get('qa_questions', [])), 
                              height=150,
                              help="è©•ä¾¡ã—ãŸã„è³ªå•ã‚’1è¡Œãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        answers = st.text_area("å›ç­”ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ã€è³ªå•ã¨é †ç•ªã‚’åˆã‚ã›ã¦ãã ã•ã„ï¼‰", 
                             value="\n".join(st.session_state.get('qa_answers', [])), 
                             height=150,
                             help="è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’1è¡Œãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # è©•ä¾¡å®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_evaluation_tab"):
            questions = [q.strip() for q in questions.split('\n') if q.strip()]
            answers = [a.strip() for a in answers.split('\n') if a.strip()]
            
            if not questions:
                st.warning("è©•ä¾¡ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif len(questions) != len(answers):
                st.warning("è³ªå•ã¨å›ç­”ã®æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
                    try:
                        evaluation_payload = {
                            "questions": questions,
                            "answers": answers,
                            "contexts": ["" for _ in questions],
                            "model": st.session_state.llm_model
                        }
                        
                        response = requests.post(
                            f"{BACKEND_URL}/evaluate/", 
                            json=evaluation_payload
                        )
                        
                        if response.status_code == 200:
                            st.session_state.evaluation_results = response.json()
                            st.session_state.qa_questions = questions
                            st.session_state.qa_answers = answers
                            st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            st.rerun()
                        else:
                            st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {response.text}")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # è©•ä¾¡çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("è©•ä¾¡çµæœ")
    if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
        eval_results = st.session_state.evaluation_results
        
        # è©•ä¾¡çµæœã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
        st.subheader("è©•ä¾¡çµæœã‚µãƒãƒªãƒ¼")
        
        # ã‚¹ã‚³ã‚¢ã®è¡¨ç¤º
        if 'scores' in eval_results:
            scores = eval_results['scores']
            st.write("### ã‚¹ã‚³ã‚¢")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§", f"{scores.get('faithfulness', 0):.2f}")
            with col2:
                st.metric("å›ç­”é–¢é€£æ€§", f"{scores.get('answer_relevancy', 0):.2f}")
            with col3:
                st.metric("æ–‡è„ˆå†ç¾ç‡", f"{scores.get('context_recall', 0):.2f}")
            with col4:
                st.metric("æ–‡è„ˆé©åˆç‡", f"{scores.get('context_precision', 0):.2f}")
        
        # è©³ç´°ãªè©•ä¾¡çµæœã‚’è¡¨ç¤º
        if 'results' in eval_results:
            st.write("### è³ªå•ã”ã¨ã®è©³ç´°")
            for i, result in enumerate(eval_results['results']):
                with st.expander(f"è³ªå• {i+1}: {result.get('question', '')}"):
                    st.write(f"**è³ªå•**: {result.get('question', '')}")
                    st.write(f"**å›ç­”**: {result.get('answer', '')}")
                    st.write(f"**ã‚¹ã‚³ã‚¢**: {result.get('score', 'N/A')}")
                    if 'details' in result:
                        st.json(result['details'])
    else:
        st.info("è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# ã‚¿ãƒ–3: ä¸€æ‹¬è©•ä¾¡
with tab3:
    if 'uploaded_file_bytes' not in st.session_state:
        st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    st.header("ä¸€æ‹¬è©•ä¾¡")
    
    if 'bulk_evaluation_results' in st.session_state and st.session_state.bulk_evaluation_results:
        st.subheader("ä¸€æ‹¬è©•ä¾¡çµæœ")
        st.json(st.session_state.bulk_evaluation_results)
    else:
        st.info("ä¸€æ‹¬è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    if st.button("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œ", key="bulk_evaluate_button_1"):
        with st.spinner("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"):
            try:
                response = requests.post(f"{BACKEND_URL}/bulk_evaluate/")
                if response.status_code == 200:
                    st.session_state.bulk_evaluation_results = response.json()
                    st.success("ä¸€æ‹¬è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.error(f"ä¸€æ‹¬è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {response.text}")
            except Exception as e:
                st.error(f"ä¸€æ‹¬è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ã‚¿ãƒ–4: æ¯”è¼ƒ
# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¿ãƒ–
with tab_chatbot:
    st.header("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ã‚’ç”Ÿæˆ
        response_text = ""
        with st.chat_message("assistant"):
            try:
                if not os.getenv("OPENAI_API_KEY"):
                    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    response_text = "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™
                messages = [{"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}]
                messages.extend([{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_messages])
                
                # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦APIã‚’å‘¼ã³å‡ºã—
                if st.session_state.chat_model in ["gpt-4o-mini", "gpt-3.5-turbo"]:
                    # OpenAI APIã‚’ä½¿ç”¨
                    api_key = os.getenv("OPENAI_API_KEY")
                    if not api_key:
                        response_text = "ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                    else:
                        try:
                            client = OpenAI(api_key=api_key)
                            response = client.chat.completions.create(
                                model=st.session_state.chat_model,
                                messages=messages,
                                temperature=0.7,
                                max_tokens=1000
                            )
                            response_text = response.choices[0].message.content
                        except Exception as e:
                            response_text = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                else:
                    # ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼ˆä¾‹ã¨ã—ã¦ã®å®Ÿè£…ï¼‰
                    response_text = f"{st.session_state.chat_model} ã‹ã‚‰ã®å¿œç­”: ã‚ãªãŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€Œ{prompt}ã€ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n\nï¼ˆæ³¨: ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼å¿œç­”ã§ã™ï¼‰"
                
                st.markdown(response_text)
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.chat_messages.append({"role": "assistant", "content": response_text})
                
            except Exception as e:
                error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_msg)
                st.session_state.chat_messages.append({"role": "assistant", "content": error_msg})
        
        # ç”»é¢ã‚’æ›´æ–°
        st.rerun()

with tab4:
    if 'uploaded_file_bytes' not in st.session_state:
        st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    st.header("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
    
    if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
        st.subheader("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
        
        # è©•ä¾¡çµæœã‚’DataFrameã«å¤‰æ›
        eval_results = st.session_state.evaluation_results
        if 'results' in eval_results:
            df_data = []
            for i, result in enumerate(eval_results['results']):
                row = {
                    'è³ªå•ç•ªå·': i+1,
                    'è³ªå•': result.get('question', ''),
                    'å›ç­”': result.get('answer', '')
                }
                if 'details' in result:
                    for k, v in result['details'].items():
                        if isinstance(v, (int, float)):
                            row[k] = v
                df_data.append(row)
            
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(df)
                
                # ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–
                score_cols = [col for col in df.columns if col not in ['è³ªå•ç•ªå·', 'è³ªå•', 'å›ç­”']]
                if score_cols:
                    st.subheader("ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ")
                    fig = px.bar(df, x='è³ªå•ç•ªå·', y=score_cols, 
                                title="è³ªå•ã”ã¨ã®ã‚¹ã‚³ã‚¢æ¯”è¼ƒ",
                                labels={'value': 'ã‚¹ã‚³ã‚¢', 'variable': 'è©•ä¾¡é …ç›®', 'è³ªå•ç•ªå·': 'è³ªå•ç•ªå·'})
                    st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("æ¯”è¼ƒã™ã‚‹è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡ã¾ãŸã¯ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        # --- è‡ªå‹•ç”ŸæˆQAã‚»ãƒƒãƒˆå„ªå…ˆã§åˆ©ç”¨ ---
        auto_questions = st.session_state.get('qa_questions', None)
        auto_answers = st.session_state.get('qa_answers', None)
        if auto_questions:
            st.markdown("#### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¾ã™")
            questions = auto_questions
            st.write("\n".join([f"Q{i+1}: {q}" for i, q in enumerate(questions)]))
        else:
            questions_input = st.text_area("1è¡Œã«1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150, 
                                           value="ä¸»ãªãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æŠ€è¡“ã«ã¯ä½•ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨å†å¸°çš„æ–‡å­—åˆ†å‰²ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ")
            questions = [q.strip() for q in questions_input.split('\n') if q.strip()]

        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_evaluation"):
            if not questions:
                st.warning("æœ€ä½1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"):
                    try:
                        # 1. è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                        answers = []
                        contexts = []
                        # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Œã°åˆ©ç”¨ ---
                        if auto_answers and len(auto_answers) == len(questions):
                            answers = auto_answers
                            st.success("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                        else:
                            # å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¿½åŠ 
                            st.warning("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            st.stop()

                        # 2. è©•ä¾¡ã‚’å®Ÿè¡Œ
                        evaluation_payload = {
                            "questions": questions,
                            "answers": answers,
                            "contexts": ["" for _ in questions],  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ç©ºã§ä»®è¨­å®š
                            "model": st.session_state.llm_model
                        }
                        
                        eval_response = requests.post(f"{BACKEND_URL}/evaluate/", json=evaluation_payload)
                        if eval_response.status_code == 200:
                            st.session_state.evaluation_results = eval_response.json()
                            st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            # è©•ä¾¡çµæœã‚’è¡¨ç¤ºã™ã‚‹ã‚¿ãƒ–ã«ç§»å‹•
                            st.session_state.active_tab = "è©•ä¾¡"
                            st.rerun()
                        else:
                            st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {eval_response.text}")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.warning(f"chunk_size <= overlap ã¨ãªã‚‹ä¸æ­£ãªçµ„ã¿åˆã‚ã›ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã—ãŸ: ({embedding}, {strategy}, {size}, {overlap})")
                    # é€²æ—ãƒãƒ¼ã®è¨­å®š
                    progress_bar = st.progress(0)
                    total_tasks = len(futures)
                    completed_tasks = 0
                    for future in concurrent.futures.as_completed(futures):
                        result = future.result()
                        if result is not None:
                            answers.append(result['answer'])
                            contexts.append(result['context'])
                        completed_tasks += 1
                        progress_bar.progress(min(completed_tasks / total_tasks, 1.0))
                    progress_bar.empty()
                    st.session_state.evaluation_results = {"answers": answers, "contexts": contexts}
                    st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        if st.session_state.evaluation_results:
            st.subheader("è©•ä¾¡æŒ‡æ¨™")
            st.write("è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
            # evaluation_resultsãŒãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆã«å¯¾å¿œ
            eval_results = st.session_state.evaluation_results
            if isinstance(eval_results, list):
                results_df = pd.DataFrame(eval_results)
            else:
                results_df = pd.DataFrame([eval_results])
            # è‹±èªâ†’æ—¥æœ¬èªã®æŒ‡æ¨™åãƒãƒƒãƒ”ãƒ³ã‚°
            METRIC_JA = {
                "faithfulness": "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§",
                "answer_relevancy": "å›ç­”é–¢é€£æ€§",
                "context_recall": "æ–‡è„ˆå†ç¾ç‡",
                "context_precision": "æ–‡è„ˆé©åˆç‡"
            }

            # DataFrameã®ã‚«ãƒ©ãƒ åã‚‚æ—¥æœ¬èªã«å¤‰æ›ã—ã¦è¡¨ç¤º
            results_df_ja = results_df.rename(columns=METRIC_JA)
            st.dataframe(results_df_ja)

            # Plotting
            metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
            available_metrics = [m for m in metrics if m in results_df.columns]

            if available_metrics:
                plot_df = results_df[available_metrics].T.reset_index()
                plot_df['index'] = plot_df['index'].map(METRIC_JA)
                plot_df.columns = ['æŒ‡æ¨™', 'ã‚¹ã‚³ã‚¢']

                # Performance Rankingé¢¨ æ¨ªæ£’ã‚°ãƒ©ãƒ•
                fig_bar = px.bar(
                    plot_df,
                    y='æŒ‡æ¨™',
                    x='ã‚¹ã‚³ã‚¢',
                    orientation='h',
                    text='ã‚¹ã‚³ã‚¢',
                    title="Performance Ranking",
                    labels={"æŒ‡æ¨™": "Metric", "ã‚¹ã‚³ã‚¢": "Score"},
                )
                fig_bar.update_traces(texttemplate='%{x:.3f}', textposition='outside')
                fig_bar.update_layout(
                    title={
                        'text': "RAG Strategy Performance Ranking<br><sup>Error bars show standard deviation â€¢ * indicates statistical significance</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    font=dict(size=16),
                    height=550,
                    margin=dict(l=40, r=40, t=80, b=40),
                    showlegend=False
                )
                st.plotly_chart(fig_bar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_bar:
                    st.session_state['eval_figs'].append(fig_bar)
                st.markdown('<br>', unsafe_allow_html=True)

                # RAGAS Metrics Comparisoné¢¨ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
                import plotly.graph_objects as go
                metrics_en = ['Faithfulness', 'Answer Relevancy', 'Context Recall', 'Context Precision']
                metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
                r_values = [results_df[m].iloc[0] if m in results_df.columns else 0 for m in metrics]
                fig_radar = go.Figure()
                fig_radar.add_trace(go.Scatterpolar(
                    r=r_values,
                    theta=metrics_en,
                    fill='toself',
                    name='Sample'
                ))
                fig_radar.update_layout(
                    title={
                        'text': "RAGAS Metrics Comparison<br><sup>All metrics normalized to 0-1 scale</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    showlegend=True,
                    font=dict(size=16),
                    height=600,
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                st.plotly_chart(fig_radar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_radar:
                    st.session_state['eval_figs'].append(fig_radar)
                st.markdown('<br>', unsafe_allow_html=True)
            else:
                st.warning("è©•ä¾¡æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡APIã®è¿”å´å†…å®¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

    with tab3:
        st.header("ä¸€æ‹¬è©•ä¾¡")
        st.markdown("Embeddingãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å…¨çµ„ã¿åˆã‚ã›ã§ä¸€æ‹¬è‡ªå‹•è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚")

        # Embeddingãƒ¢ãƒ‡ãƒ«ã®è¤‡æ•°é¸æŠ
        embedding_options = {
            "bge-smallï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é«˜é€Ÿï¼‰": "huggingface_bge_small",
            "MiniLMï¼ˆè»½é‡ãƒ»å¤šè¨€èªï¼‰": "huggingface_miniLM",
            "OpenAI": "openai",
        }
        embedding_labels = list(embedding_options.keys())
        embedding_values = list(embedding_options.values())
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§bge-smallã‚’é¸æŠ
        selected_labels = st.multiselect(
            "Embeddingãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            embedding_labels,
            default=[embedding_labels[0]],
            key="bulk_embeddings_tab3"
        )
        selected_embeddings = [embedding_options[label] for label in selected_labels]

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¤‡æ•°é¸æŠ
        chunk_methods = st.multiselect(
            "ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ã‚’é¸æŠ",
            ["fixed", "recursive", "semantic", "sentence", "paragraph"],
            default=["fixed", "recursive", "semantic"]
        )
        chunk_sizes = st.multiselect(
            "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰",
            [128, 256, 500, 1000, 1500, 2000],
            default=[500, 1000]
        )
        chunk_overlaps = st.multiselect(
            "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆæ–‡å­—æ•°ï¼‰",
            [0, 32, 64, 100, 200, 300],
            default=[0, 100, 200]
        )
        st.caption("â€»Embeddingãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å…¨çµ„ã¿åˆã‚ã›ã§è‡ªå‹•ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã™")

        if st.button("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œ", key="bulk_evaluate_button_2"):
            # ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if not st.session_state.get("text"):
                st.error("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
                
            with st.spinner("ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œä¸­..."):
                import concurrent.futures
                from concurrent.futures import ThreadPoolExecutor
                import time
                
                bulk_results = []
                invalid_combinations = []
                valid_combinations = []
                
                # æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›ã®ã¿æŠ½å‡º
                for method in chunk_methods:
                    if method in ["fixed", "recursive", "semantic"]:
                        for size in chunk_sizes:
                            for overlap in chunk_overlaps:
                                if size > overlap:
                                    valid_combinations.append((method, size, overlap))
                                else:
                                    invalid_combinations.append((method, size, overlap))
                    else:
                        # size/overlapã‚’ä½¿ã‚ãªã„æ–¹å¼ã¯ä¸€åº¦ã ã‘Noneã§è¿½åŠ 
                        valid_combinations.append((method, None, None))
                
                if not valid_combinations:
                    st.error("æœ‰åŠ¹ãªãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚chunk_size > overlap ã¨ãªã‚‹ã‚ˆã†ã«é¸æŠã—ã¦ãã ã•ã„ã€‚")
                    st.stop()
                
                if invalid_combinations:
                    st.warning(f"chunk_size <= overlap ã¨ãªã‚‹ä¸æ­£ãªçµ„ã¿åˆã‚ã›ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã—ãŸ: {invalid_combinations}")
                
                # é€²æ—ãƒãƒ¼ã€ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã®è¨­å®š
                progress_bar = st.progress(0)
                progress_text = st.empty()
                status_display = st.empty()
                total_tasks = len(selected_embeddings) * len(valid_combinations)
                
                # å®Œäº†ã‚¿ã‚¹ã‚¯æ•°ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆï¼ˆãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
                completed_tasks = [0]
                
                # è©•ä¾¡ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
                def evaluate_single(emb, method, size, overlap):
                    try:
                        # ãƒ†ã‚­ã‚¹ãƒˆã®å­˜åœ¨ã‚’å†ç¢ºèª
                        text = st.session_state.get("text")
                        qa_questions = st.session_state.get("qa_questions", [])
                        qa_answers = st.session_state.get("qa_answers", [])
                        
                        if not text:
                            st.error("è©•ä¾¡å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                            return None
                            
                        if not qa_questions or not qa_answers:
                            st.error("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€Q&Aã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                            return None
                            
                        payload = {
                            "embedding_model": emb,
                            "chunk_methods": [method],
                            "chunk_sizes": [size] if size is not None else [1000],
                            "chunk_overlaps": [overlap] if overlap is not None else [200],
                            "text": text,
                            "questions": qa_questions,
                            "answers": qa_answers,
                        }
                        
                        response = requests.post(
                            f"{BACKEND_URL}/bulk_evaluate/", 
                            json=payload, 
                            timeout=300
                        )
                        
                        completed_tasks[0] += 1
                        progress_bar.progress(min(completed_tasks[0] / total_tasks, 1.0))
                        progress_text.text(f"å®Œäº†: {completed_tasks[0]} / {total_tasks} ä»¶")
                        
                        if response.status_code == 200:
                            return response.json()
                        else:
                            st.error("è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°:")
                            st.json({
                                "status_code": response.status_code,
                                "error": response.text,
                                "request_payload": payload
                            })
                            return None
                            
                    except requests.exceptions.RequestException as e:
                        st.error(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                        return None
                    except json.JSONDecodeError as e:
                        st.error(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        return None
                    except Exception as e:
                        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        import traceback
                        st.text(traceback.format_exc())
                        return None
                
                # ãƒ‡ãƒãƒƒã‚°ç”¨: ä¸¦åˆ—å‡¦ç†ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
                bulk_results = []
                
                try:
                    for emb in selected_embeddings:
                        for method, size, overlap in valid_combinations:
                            # ç¾åœ¨ã®è©•ä¾¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
                            status_display.info(f"è©•ä¾¡ä¸­: {emb}, {method}, size={size}, overlap={overlap}")
                            
                            # è©•ä¾¡ã‚’å®Ÿè¡Œ
                            result = evaluate_single(emb, method, size, overlap)
                            
                            if result:
                                bulk_results.append(result)
                                status_display.success(f"å®Œäº†: {emb}, {method}, size={size}, overlap={overlap}")
                            else:
                                status_display.warning(f"ã‚¹ã‚­ãƒƒãƒ—: {emb}, {method}, size={size}, overlap={overlap}")
                            
                            # å°‘ã—å¾…æ©Ÿï¼ˆUIã®æ›´æ–°ã®ãŸã‚ï¼‰
                            import time
                            time.sleep(0.1)
                    
                    # æœ€çµ‚çš„ãªé€²æ—è¡¨ç¤º
                    progress_text.success(f"å®Œäº†: {total_tasks} / {total_tasks} ä»¶")
                    
                    # é€²æ—ãƒãƒ¼ã‚’100%ã«
                    progress_bar.progress(1.0)
                    
                    # æœ€çµ‚çš„ãªã‚µãƒãƒªã‚’è¡¨ç¤º
                    if bulk_results:
                        status_display.success(f"è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ (æˆåŠŸ: {len(bulk_results)}ä»¶)")
                    else:
                        status_display.error("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ‰åŠ¹ãªçµæœã¯å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                except Exception as e:
                    status_display.error(f"è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                
                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                if bulk_results:
                    try:
                        # çµæœãŒãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã®å ´åˆã«ãƒ•ãƒ©ãƒƒãƒˆåŒ–
                        flat_results = []
                        for result in bulk_results:
                            if isinstance(result, list):
                                flat_results.extend(result)
                            else:
                                flat_results.append(result)
                        
                        st.session_state.bulk_evaluation_results = flat_results
                    except Exception as e:
                        status_display.error(f"çµæœã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                else:
                    status_display.error("ä¸€æ‹¬è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
                    
                # çµæœã®è©³ç´°ã¯ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
                if bulk_results:
                    print("\n=== è©•ä¾¡çµæœã‚µãƒãƒª ===")
                    print(f"æˆåŠŸ: {len(bulk_results)}ä»¶")
                    for i, result in enumerate(bulk_results, 1):
                        print(f"\n--- çµæœ {i} ---")
                        print(json.dumps(result, ensure_ascii=False, indent=2))

        if st.session_state.bulk_evaluation_results:
            st.subheader("ä¸€æ‹¬è©•ä¾¡çµæœ")
            st.write("ä¸€æ‹¬è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.bulk_evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º

            # çµæœã‚’DataFrameã«å¤‰æ›
            eval_results = st.session_state.bulk_evaluation_results
            if isinstance(eval_results, list):
                results_df = pd.DataFrame(eval_results)
            else:
                results_df = pd.DataFrame([eval_results])
            
            # å¿…è¦ã‚«ãƒ©ãƒ è£œå®Œãƒ»ãƒ©ãƒ™ãƒ«åˆ—è¿½åŠ 
            required_cols = {
                'avg_chunk_len', 'num_chunks', 'overall_score', 'chunk_strategy', 'embedding_model',
                'faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness'
            }
            missing_cols = required_cols - set(results_df.columns)
            
            if 'chunk_method' in results_df.columns and 'chunk_strategy' not in results_df.columns:
                results_df['chunk_strategy'] = results_df['chunk_method']
                st.info('chunk_strategyåˆ—ã‚’chunk_methodã‹ã‚‰è£œå®Œã—ã¾ã—ãŸ')
            
            if len(results_df) > 0:
                # ä¸è¶³ã‚«ãƒ©ãƒ ã®è£œå®Œ
                if missing_cols:
                    st.info(f'ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}ã€‚è‡ªå‹•ã§ä»®å€¤ã‚’è£œå®Œã—ã¾ã™ã€‚')
                    for col in missing_cols:
                        if col == 'chunk_strategy':
                            results_df[col] = 'unknown'
                        else:
                            results_df[col] = 0.0
                
                # ãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ ï¼ˆchunk_sizeãŒã‚ã‚Œã°å«ã‚ã‚‹ï¼‰
                if 'chunk_size' in results_df.columns:
                    results_df['label'] = results_df['chunk_strategy'] + '-' + results_df['chunk_size'].astype(str)
                else:
                    results_df['label'] = results_df['chunk_strategy']
                
                # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆï¼ˆè‰²ã‚’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦è¨­å®šï¼‰
                # ãƒãƒ–ãƒ«ã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
                size_scale = 20  # ãƒãƒ–ãƒ«ã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
                
                fig_bubble = px.scatter(
                    results_df,
                    x="num_chunks",  # ã‚«ãƒ©ãƒ åã‚’num_chunksã«ä¿®æ­£
                    y="avg_chunk_len",
                    size=[min(s * size_scale, 50) for s in results_df["overall_score"]],  # ãƒãƒ–ãƒ«ã®æœ€å¤§ã‚µã‚¤ã‚ºã‚’åˆ¶é™
                    color="overall_score",  # è‰²ã‚’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦è¨­å®š
                    hover_name="label",
                    text="label",
                    title="Chunk Distribution vs Performance (Bulk Evaluation)",
                    labels={
                        "num_chunks": "Number of Chunks",
                        "avg_chunk_len": "Average Chunk Size (characters)",
                        "overall_score": "Performance Score"
                    },
                    color_continuous_scale=px.colors.sequential.Viridis,
                    color_continuous_midpoint=0.5,  # è‰²ã®ä¸­å¿ƒå€¤ã‚’0.5ã«è¨­å®š
                )
                
                # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ›´æ–°
                fig_bubble.update_traces(
                    textposition='middle center',  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ–ãƒ«ã®ä¸­å¤®ã«é…ç½®
                    textfont=dict(
                        size=12,  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å¤§ãã
                        color='white',  # ãƒ†ã‚­ã‚¹ãƒˆã®è‰²ã‚’ç™½ã«
                        family='Arial',  # ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æŒ‡å®š
                    ),
                    marker=dict(
                        line=dict(width=1, color='DarkSlateGrey'),
                        opacity=0.8  # ãƒãƒ–ãƒ«ã®é€æ˜åº¦ã‚’èª¿æ•´
                    ),
                    textfont_size=12,  # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
                    textfont_color='white',  # ãƒ†ã‚­ã‚¹ãƒˆã®è‰²
                    textfont_family='Arial',  # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ³ãƒˆ
                    texttemplate='%{text}<br>Score: %{marker.color:.2f}',  # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                    hovertemplate=
                    '<b>%{hovertext}</b><br>' +
                    'Chunks: %{x}<br>' +
                    'Avg Size: %{y}<br>' +
                    'Score: %{marker.color:.2f}<extra></extra>',  # ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                )
                
                fig_bubble.update_layout(
                    title={
                        'text': "Chunk Distribution vs Performance (Bulk Evaluation)<br><sup>Bubble size = performance</sup>",
                        'x': 0.5,
                        'xanchor': 'center'
                    },
                    coloraxis_colorbar=dict(title="Performance Score"),
                    font=dict(size=16),
                    height=600,
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                
                # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
                st.plotly_chart(fig_bubble, use_container_width=True)
                st.markdown('<br>', unsafe_allow_html=True)
                
                # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤º
                fig_radar = go.Figure()
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å®šç¾©
                metrics = ["faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]
                metrics_jp = ["ä¿¡é ¼æ€§", "å›ç­”ã®é–¢é€£æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å†ç¾æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ­£ç¢ºæ€§", "å›ç­”ã®æ­£ç¢ºæ€§"]
                
                # ãƒ¢ãƒ‡ãƒ«ãŒ1ã¤ã®å ´åˆã§ã‚‚ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
                models = results_df['embedding_model'].unique() if 'embedding_model' in results_df.columns else ["default"]
                
                for model in models:
                    model_data = results_df[results_df['embedding_model'] == model] if 'embedding_model' in results_df.columns else results_df
                    
                    # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¹³å‡å€¤ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯0.5ã§è£œå®Œï¼‰
                    r_values = [model_data[m].mean() if m in model_data.columns else 0.5 for m in metrics]
                    
                    fig_radar.add_trace(go.Scatterpolar(
                        r=r_values,
                        theta=metrics_jp,  # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨
                        fill='toself',
                        name=f"{model}-{model_data['chunk_size'].iloc[0] if 'chunk_size' in model_data.columns else ''}" if len(models) > 1 else "è©•ä¾¡çµæœ",
                        hovertemplate='%{theta}: %{r:.2f}<extra></extra>',
                        line=dict(width=2)
                    ))
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                fig_radar.update_layout(
                    title={
                        'text': "è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ",
                        'x': 0.5,
                        'xanchor': 'center',
                        'y': 0.95,
                        'font': {'size': 18}
                    },
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, 1],
                            tickfont=dict(size=10),
                            tickangle=0,
                            tickformat='.1f',
                            gridwidth=1
                        ),
                        angularaxis=dict(
                            rotation=90,
                            direction='clockwise',
                            tickfont=dict(size=12),
                            gridwidth=1
                        ),
                        bgcolor='rgba(0,0,0,0.02)'
                    ),
                    showlegend=len(models) > 1,
                    legend=dict(
                        orientation='h',
                        yanchor='bottom',
                        y=1.15,
                        xanchor='center',
                        x=0.5,
                        font=dict(size=12)
                    ),
                    margin=dict(l=60, r=60, t=100, b=60),
                    height=600,
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_radar, use_container_width=True)
                st.markdown('<br>', unsafe_allow_html=True)
                
                # çµæœã‚’DataFrameã«å¤‰æ›
            results_df = pd.DataFrame(st.session_state.bulk_evaluation_results)

            import plotly.graph_objects as go  # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”¨
            # --- è©•ä¾¡æ–¹æ³•ï¼ˆãƒãƒ£ãƒ³ã‚¯æ–¹å¼ï¼‰ã”ã¨ã®é•ã„ã‚’ã¾ã¨ã‚ã¦å¯è¦–åŒ– ---
            st.subheader("è©•ä¾¡æ–¹æ³•ã”ã¨ã®æ¯”è¼ƒï¼ˆãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥å˜ä½ã§é›†ç´„ï¼‰")
            # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®è¿”å´å€¤ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã¦ä¿®æ­£
            agg_cols = ["overall_score", "faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness", "avg_chunk_len", "num_chunks"]
            missing_cols = [col for col in agg_cols if col not in results_df.columns]
            if missing_cols:
                st.warning(f"é›†ç´„ã‚°ãƒ©ãƒ•æç”»ã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®è¿”å´å€¤ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                agg_df = results_df.groupby("chunk_strategy")[agg_cols].mean().reset_index()

                # 1. æ°´å¹³æ£’ã‚°ãƒ©ãƒ•ï¼ˆç·åˆã‚¹ã‚³ã‚¢ï¼‰
                fig_bar = px.bar(
                    agg_df,
                    y="chunk_strategy",
                    x="overall_score",
                    orientation="h",
                    text="overall_score",
                    title="Performance Ranking",
                    labels={"chunk_strategy": "Chunking Strategy", "overall_score": "Overall Performance Score"},
                )
                fig_bar.update_traces(texttemplate='%{x:.3f}', textposition='outside')
                fig_bar.update_layout(
                    title={
                        'text': "RAG Strategy Performance Ranking<br><sup>Error bars show standard deviation â€¢ * indicates statistical significance</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    font=dict(size=16),
                    height=550,
                    margin=dict(l=40, r=40, t=80, b=40),
                    showlegend=False
                )
                st.plotly_chart(fig_bar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []

# --- ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®æ¯”è¼ƒ ---
if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
    st.subheader("ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®æ¯”è¼ƒ")
    
    # è©•ä¾¡çµæœã‚’DataFrameã«å¤‰æ›
    eval_results = st.session_state.evaluation_results
    if isinstance(eval_results, list):
        results_df = pd.DataFrame(eval_results)
    else:
        results_df = pd.DataFrame([eval_results])
    
    score_metrics = [
        ("overall_score", "ç·åˆã‚¹ã‚³ã‚¢(åŠ é‡å¹³å‡)"),
        ("faithfulness", "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§"),
        ("answer_relevancy", "å›ç­”é–¢é€£æ€§"),
        ("context_recall", "æ–‡è„ˆå†ç¾ç‡"),
        ("context_precision", "æ–‡è„ˆé©åˆç‡"),
        ("answer_correctness", "å›ç­”æ­£ç¢ºæ€§")
    ]
    
    for metric, label in score_metrics:
        if metric in results_df.columns:
            st.markdown(f"#### {label}ï¼šãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ã®æ¯”è¼ƒ")
            # 2ã‚«ãƒ©ãƒ ã®å¹…æ¯”ç‡ã‚’èª¿æ•´ã—ã‚°ãƒ©ãƒ•ãŒåºƒããªã‚‹ã‚ˆã†ã«
            col1, col2 = st.columns([3,2])  # å·¦ã‚’åºƒã‚ã«
            
            with col1:
                st.markdown(f"##### ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«è©•ä¾¡æ–¹æ³•åˆ¥ã®æ¯”è¼ƒ")
                fig1 = px.bar(
                    results_df,
                    x="chunk_strategy",
                    y=metric,
                    color="embedding_model",
                    barmode="group",
                    title=f"{label}ï¼šãƒ¢ãƒ‡ãƒ«ã”ã¨ã«è©•ä¾¡æ–¹æ³•åˆ¥ã®æ¯”è¼ƒ",
                    labels={"chunk_strategy": "è©•ä¾¡æ–¹æ³•ï¼ˆãƒãƒ£ãƒ³ã‚¯æ–¹å¼ï¼‰", "embedding_model": "ãƒ¢ãƒ‡ãƒ«", metric: label}
                )
                fig1.update_layout(height=600, margin=dict(l=40, r=40, t=80, b=40), legend=dict(font=dict(size=16)))
                st.plotly_chart(fig1, use_container_width=True)
                
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig1:
                    st.session_state['eval_figs'].append(fig1)
                
                st.markdown('<br>', unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"##### è©•ä¾¡æ–¹æ³•ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«åˆ¥ã®æ¯”è¼ƒ")
                fig2 = px.bar(
                    results_df,
                    x="embedding_model",
                    y=metric,
                    color="chunk_strategy",
                    barmode="group",
                    title=f"{label}ï¼šè©•ä¾¡æ–¹æ³•ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«åˆ¥ã®æ¯”è¼ƒ",
                    labels={"embedding_model": "ãƒ¢ãƒ‡ãƒ«", "chunk_strategy": "è©•ä¾¡æ–¹æ³•ï¼ˆãƒãƒ£ãƒ³ã‚¯æ–¹å¼ï¼‰", metric: label}
                )
                # ã‚°ãƒ©ãƒ•2ã‚‚åŒæ§˜ã«ã‚†ã¨ã‚Šã‚’æŒãŸã›ã‚‹
                fig2.update_layout(height=600, margin=dict(l=40, r=40, t=80, b=40), legend=dict(font=dict(size=16)))
                st.plotly_chart(fig2, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig2:
                    st.session_state['eval_figs'].append(fig2)
                st.markdown('<br>', unsafe_allow_html=True)
            # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚„è¡¨ã‚‚æ—¢å­˜é€šã‚Šè¡¨ç¤º
            fig = go.Figure()
            for model in results_df['embedding_model'].unique():
                model_data = results_df[results_df['embedding_model'] == model]
                fig.add_trace(go.Scatterpolar(
                    r=[model_data[m].mean() for m in score_metrics[1:]],
                    theta=[label for _, label in score_metrics[1:]],
                    fill='toself',
                    name=model
                ))
            fig.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                showlegend=True,
                title=f"{label}ï¼šãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"
            )
            # ã‚°ãƒ©ãƒ•ãŒæ½°ã‚Œãªã„ã‚ˆã†ã«é«˜ã•ãƒ»ãƒãƒ¼ã‚¸ãƒ³ãƒ»å‡¡ä¾‹ã‚µã‚¤ã‚ºã‚’èª¿æ•´
            fig.update_layout(height=600, margin=dict(l=40, r=40, t=80, b=40), legend=dict(font=dict(size=16)))
            st.plotly_chart(fig, use_container_width=True)
            st.markdown('<br>', unsafe_allow_html=True)
            
            # --- æ¯”è¼ƒè¡¨ï¼ˆå…¨æŒ‡æ¨™ï¼‰ ---
            st.markdown("#### å…¨æŒ‡æ¨™ã®æ¯”è¼ƒè¡¨")
            # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¤‰æ›ç”¨ãƒãƒƒãƒ”ãƒ³ã‚°
            METRIC_JA = {
                "overall_score": "ç·åˆã‚¹ã‚³ã‚¢(åŠ é‡å¹³å‡)",
                "faithfulness": "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§",
                "answer_relevancy": "å›ç­”é–¢é€£æ€§",
                "context_recall": "æ–‡è„ˆå†ç¾ç‡",
                "context_precision": "æ–‡è„ˆé©åˆç‡",
                "answer_correctness": "å›ç­”æ­£ç¢ºæ€§",
                "embedding_model": "Embeddingãƒ¢ãƒ‡ãƒ«",
                "chunk_strategy": "ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥"
            }
            results_df_ja = results_df.rename(columns=METRIC_JA)
            st.dataframe(results_df_ja, use_container_width=True)

        # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒãƒ£ãƒ³ã‚¯åŒ–ã®ã¿å®Ÿè¡Œ ---
        st.sidebar.markdown("## ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å°‚ç”¨ï¼‰")
        chunk_method = st.sidebar.selectbox(
            "ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹å¼ã‚’é¸æŠ",
            ["fixed", "recursive", "semantic", "sentence", "paragraph"],
            index=0
        )
        chunk_size = st.sidebar.selectbox(
            "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰",
            [128, 256, 500, 1000, 1500, 2000],
            index=2
        ) if chunk_method in ["fixed", "recursive", "semantic"] else None
        chunk_overlap = st.sidebar.selectbox(
            "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆæ–‡å­—æ•°ï¼‰",
            [0, 32, 64, 100, 200, 300],
            index=0
        ) if chunk_method in ["fixed", "recursive", "semantic"] else None
        if st.sidebar.button("ãƒãƒ£ãƒ³ã‚¯åŒ–ã‚’å®Ÿè¡Œ", help="é¸æŠã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–"):
            # ãƒãƒ£ãƒ³ã‚¯åŒ–APIå‘¼ã³å‡ºã—
            import requests
            BACKEND_URL = st.secrets.get('BACKEND_URL', 'http://localhost:8000')
            payload = {
                "chunk_method": chunk_method,
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "text": st.session_state.get('text', '')
            }
            try:
                response = requests.post(f"{BACKEND_URL}/chunk_text/", json=payload)
                if response.status_code == 200:
                    chunk_result = response.json()
                    st.session_state['sidebar_chunk_result'] = chunk_result
                    st.sidebar.success(f"ãƒãƒ£ãƒ³ã‚¯åŒ–æˆåŠŸ: {chunk_result.get('num_chunks', 0)}å€‹")
                else:
                    st.sidebar.error(f"ãƒãƒ£ãƒ³ã‚¯åŒ–å¤±æ•—: {response.text}")
            except Exception as e:
                st.sidebar.error(f"ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä¾‹å¤–: {e}")

        # ãƒãƒ£ãƒ³ã‚¯åŒ–çµæœè¡¨ç¤º
        if 'sidebar_chunk_result' in st.session_state:
            chunk_result = st.session_state['sidebar_chunk_result']
            st.sidebar.markdown(f"- ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_result.get('num_chunks', 0)}")
            st.sidebar.markdown(f"- å¹³å‡ãƒãƒ£ãƒ³ã‚¯é•·: {chunk_result.get('avg_chunk_len', 0)}")
            st.sidebar.markdown("---")
            st.sidebar.markdown("#### ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆï¼ˆå…ˆé ­5ä»¶ï¼‰")
            for i, chunk in enumerate(chunk_result.get('chunks', [])[:5]):
                st.sidebar.markdown(f"**{i+1}**: {chunk[:80]}{'...' if len(chunk)>80 else ''}")

        # --- ä¸€æ‹¬è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ ---
        if st.session_state.get('run_bulk_eval', False):
            with st.spinner("ä¸€æ‹¬è©•ä¾¡ä¸­...ï¼ˆå…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™ï¼‰"):
                import requests
                BACKEND_URL = st.secrets.get('BACKEND_URL', 'http://localhost:8000')
                payload = {
                    "embedding_model": st.session_state.get('selected_embedding_model', 'openai'),
                    "chunk_methods": chunk_methods,
                    "chunk_sizes": chunk_sizes,
                    "chunk_overlaps": chunk_overlaps,
                    # ä»–ã®å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚ã“ã“ã«è¿½åŠ 
                }
                try:
                    response = requests.post(f"{BACKEND_URL}/bulk_evaluate/", json=payload)
                    if response.status_code == 200:
                        results = response.json()
                        st.session_state['bulk_eval_results'] = results
                        st.success("ä¸€æ‹¬è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    else:
                        st.error(f"ä¸€æ‹¬è©•ä¾¡ã«å¤±æ•—: {response.text}")
                except Exception as e:
                    st.error(f"ä¸€æ‹¬è©•ä¾¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä¾‹å¤–: {e}")
                st.session_state['run_bulk_eval'] = False

        # --- ä¸€æ‹¬è©•ä¾¡çµæœã‚’ã‚°ãƒ©ãƒ•ãƒ»è¡¨ã«åæ˜  ---
        # --- ä¸€æ‹¬è©•ä¾¡çµæœã®è¡¨ç¤ºéƒ¨ï¼ˆå…¨æŒ‡æ¨™ç¶²ç¾…ãƒ»æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¯¾å¿œï¼‰---
        if 'bulk_eval_results' in st.session_state:
            import pandas as pd
            st.markdown("### ä¸€æ‹¬è©•ä¾¡çµæœï¼ˆå…¨çµ„ã¿åˆã‚ã›ï¼‰")
            results_df = pd.DataFrame(st.session_state['bulk_eval_results'])

            # å¿…è¦ãªæŒ‡æ¨™ã‚«ãƒ©ãƒ ä¸€è¦§
            required_cols = [
                "embedding_model", "chunk_method", "chunk_size", "chunk_overlap",
                "overall_score", "faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness", "avg_chunk_len", "num_chunks"
            ]
            # æ¬ æã‚«ãƒ©ãƒ ã‚’0.0ã§è£œå®Œ
            missing_cols = [col for col in required_cols if col not in results_df.columns]
            if missing_cols:
                st.warning(f"ä¸€æ‹¬è©•ä¾¡çµæœã«ä¸è¶³ã—ã¦ã„ã‚‹æŒ‡æ¨™ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã™: {missing_cols}ã€‚0.0ã§è£œå®Œã—ã¾ã™ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚„APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚‚ã”ç¢ºèªãã ã•ã„ã€‚")
                for col in missing_cols:
                    results_df[col] = 0.0
            # ã‚«ãƒ©ãƒ é †ã‚’çµ±ä¸€
            results_df = results_df[required_cols]

            # --- æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¤‰æ› ---
            METRIC_JA = {
                "embedding_model": "Embeddingãƒ¢ãƒ‡ãƒ«",
                "chunk_method": "ãƒãƒ£ãƒ³ã‚¯æ–¹å¼",
                "chunk_size": "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º",
                "chunk_overlap": "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—",
                "overall_score": "ç·åˆã‚¹ã‚³ã‚¢",
                "faithfulness": "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§",
                "answer_relevancy": "å›ç­”é–¢é€£æ€§",
                "context_recall": "æ–‡è„ˆå†ç¾ç‡",
                "context_precision": "æ–‡è„ˆé©åˆç‡",
                "answer_correctness": "å›ç­”æ­£ç¢ºæ€§",
                "avg_chunk_len": "å¹³å‡ãƒãƒ£ãƒ³ã‚¯é•·",
                "num_chunks": "ãƒãƒ£ãƒ³ã‚¯æ•°"
            }
            results_df_ja = results_df.rename(columns=METRIC_JA)

            # --- DataFrameã‚’æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã§è¡¨ç¤º ---
            st.dataframe(results_df_ja, use_container_width=True)

            # --- ä»¥é™ã®å…¨ã‚°ãƒ©ãƒ•ãƒ»æ¯”è¼ƒè¡¨ãƒ»PDFå‡ºåŠ›ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚‚results_df_jaã«çµ±ä¸€ ---
            # æ—¢å­˜ã®score_metricsã‚„æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚‚results_df_jaã‚’ä½¿ã†
            score_metrics = [
                (col, METRIC_JA.get(col, col)) for col in ["overall_score", "faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]
            ]
            # ã‚°ãƒ©ãƒ•æç”»

            for metric, label in score_metrics:
                if metric in results_df.columns:
                    st.markdown(f"#### {label}ï¼šãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ¥ã®æ¯”è¼ƒ")
                    # 2ã‚«ãƒ©ãƒ ã®å¹…æ¯”ç‡ã‚’èª¿æ•´ã—ã‚°ãƒ©ãƒ•ãŒåºƒããªã‚‹ã‚ˆã†ã«
                    col1, col2 = st.columns([3,2])  # å·¦ã‚’åºƒã‚ã«
                    with col1:
                        st.markdown(f"##### ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«è©•ä¾¡æ–¹æ³•ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ¥ã®æ¯”è¼ƒ")
                        fig1 = px.bar(
                            results_df,
                            x="chunk_method",
                            y=metric,
                            color="embedding_model",
                            barmode="group",
                            facet_col="chunk_size",
                            facet_row="chunk_overlap",
                            title=f"{label}ï¼šãƒ¢ãƒ‡ãƒ«ã”ã¨ã«è©•ä¾¡æ–¹æ³•ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ¥ã®æ¯”è¼ƒ",
                            labels={"chunk_method": "ãƒãƒ£ãƒ³ã‚¯æ–¹å¼", "embedding_model": "ãƒ¢ãƒ‡ãƒ«", metric: label}
                        )
                        # ã‚°ãƒ©ãƒ•1ã‚‚åŒæ§˜ã«ã‚†ã¨ã‚Šã‚’æŒãŸã›ã‚‹
                        fig1.update_layout(height=600, margin=dict(l=40, r=40, t=80, b=40), legend=dict(font=dict(size=16)))
                        st.plotly_chart(fig1, use_container_width=True)
                        st.markdown('<br>', unsafe_allow_html=True)
                    with col2:
                        st.markdown(f"##### è©•ä¾¡æ–¹æ³•ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ¥ã®æ¯”è¼ƒ")
                        fig2 = px.bar(
                            results_df,
                            x="embedding_model",
                            y=metric,
                            color="chunk_method",
                            barmode="group",
                            facet_col="chunk_size",
                            facet_row="chunk_overlap",
                            title=f"{label}ï¼šè©•ä¾¡æ–¹æ³•ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚µã‚¤ã‚ºãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ¥ã®æ¯”è¼ƒ",
                            labels={"embedding_model": "ãƒ¢ãƒ‡ãƒ«", "chunk_method": "ãƒãƒ£ãƒ³ã‚¯æ–¹å¼", metric: label}
                        )
                        # ã‚°ãƒ©ãƒ•2ã‚‚åŒæ§˜ã«ã‚†ã¨ã‚Šã‚’æŒãŸã›ã‚‹
                        fig2.update_layout(height=600, margin=dict(l=40, r=40, t=80, b=40), legend=dict(font=dict(size=16)))
                        st.plotly_chart(fig2, use_container_width=True)
                        st.markdown('<br>', unsafe_allow_html=True)
            # æ¯”è¼ƒè¡¨ã‚‚results_dfã§
            st.markdown("#### å…¨æŒ‡æ¨™ã®æ¯”è¼ƒè¡¨ï¼ˆç¶²ç¾…çš„ï¼‰")
            st.dataframe(results_df, use_container_width=True)
            # PDFå‡ºåŠ›æ©Ÿèƒ½ã‚‚results_dfã‚’åˆ©ç”¨ã—ã¦è‡ªå‹•ç”Ÿæˆ

        # --- æ“ä½œãƒœã‚¿ãƒ³ ---
        st.markdown("---")
        col_btn1, col_btn2, col_btn3 = st.columns(3)
        with col_btn1:
            if st.button("å†è©•ä¾¡ãƒ»ã‚°ãƒ©ãƒ•å†æç”»", help="æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚°ãƒ©ãƒ•ã‚’å†æç”»ã—ã¾ã™"):
                st.rerun()
        with col_btn2:
            if st.button("å…¨çµæœã‚’PDFå‡ºåŠ›ï¼ˆæ¯”è¼ƒãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰", help="å…¨ã‚°ãƒ©ãƒ•ãƒ»æ¯”è¼ƒè¡¨ã‚’PDFã§ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                st.session_state['pdf_export'] = True
        with col_btn3:
            if st.button("æ¯”è¼ƒAPIå®Ÿè¡Œ", help="ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¯”è¼ƒAPIã‚’å‘¼ã³å‡ºã—ã¦çµæœã‚’è¡¨ç¤º"):
                st.session_state['run_compare_api'] = True

        # --- PDFä¸€æ‹¬å‡ºåŠ›æ©Ÿèƒ½ ---
        if st.session_state.get('pdf_export', False):
            from fpdf import FPDF
            import tempfile
            import plotly.io as pio
            import os
            from PIL import Image
            import io
            st.info("PDFã‚’ç”Ÿæˆä¸­...")
            pdf = FPDF(orientation='L', unit='mm', format='A4')
            pdf.add_page()
            pdf.add_font('NotoSansJPVF', '', '/app/fonts/NotoSansJP-VariableFont_wght.ttf', uni=True)
            pdf.set_font('NotoSansJPVF', '', 14)
            pdf.cell(0, 10, txt="RAGè©•ä¾¡çµæœ æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ", ln=1, align='C')
            pdf.ln(2)
            # --- ç”»é¢ã«è¡¨ç¤ºã—ãŸã‚°ãƒ©ãƒ•ï¼ˆfigï¼‰ã®ã¿PDFã¸ ---
            eval_figs = st.session_state.get('eval_figs', [])
            img_paths = []
            for fig in eval_figs:
                # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
                title = fig.layout.title.text if hasattr(fig.layout, 'title') and fig.layout.title.text else ""
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as f:
                    fig.write_image(f.name, format='png', scale=2)
                    img_paths.append((f.name, None, title))

            for left, right, label in img_paths:
                pdf.add_page()  # 1ãƒšãƒ¼ã‚¸1æšé…ç½®
                pdf.set_font('NotoSansJPVF', '', 14)
                pdf.cell(0, 12, txt=f"{label}", ln=1, align='C')
                y = pdf.get_y()
                img_width = pdf.w - 40
                x_center = (pdf.w - img_width) / 2
                pdf.image(left, x=x_center, y=y, w=img_width)
                pdf.ln(img_width * 0.6 + 20)

            pdf.add_page()
            pdf.set_font('NotoSansJPVF', '', 12)
            pdf.cell(0, 10, txt="å…¨æŒ‡æ¨™ã®æ¯”è¼ƒè¡¨", ln=1)
            table_cols = ["embedding_model", "chunk_strategy"] + [m for m, _ in score_metrics]
            table_df = results_df[table_cols].copy()
            col_width = (pdf.w - 20) / len(table_df.columns)
            for col in table_df.columns:
                pdf.cell(col_width, 8, str(col), border=1)
            pdf.ln()
            for _, row in table_df.iterrows():
                for val in row:
                    pdf.cell(col_width, 8, str(val), border=1)
                pdf.ln()
            for left, right, _ in img_paths:
                try:
                    os.remove(left)
                    os.remove(right)
                except Exception:
                    pass
            pdf_bytes = pdf.output(dest='S').encode('latin1')
            st.success("PDFç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.download_button(
                label="PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pdf_bytes,
                file_name="rag_evaluation_report.pdf",
                mime="application/pdf"
            )
            st.session_state['pdf_export'] = False

        # --- æ¯”è¼ƒã‚¿ãƒ– ---
        with tab4:
            st.header("æ¯”è¼ƒ")
            st.markdown("ä¸€æ‹¬è©•ä¾¡çµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")

            # æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨æˆ¦ç•¥ã®é¸æŠ
            models = ["ollama_llama2", "openai"]
            strategies = ["rag", "ragas"]

            selected_models = st.multiselect("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", models, key="compare_models_tab4_main")
            selected_strategies = st.multiselect("æˆ¦ç•¥ã‚’é¸æŠ", strategies, key="compare_strategies_tab4_main")
        selected_models = st.multiselect("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", models, key="compare_models_tab4")
        selected_strategies = st.multiselect("æˆ¦ç•¥ã‚’é¸æŠ", strategies, key="compare_strategies_tab4")

        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_compare"):
            with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­..."):
                # QAã‚»ãƒƒãƒˆå¿…é ˆãƒã‚§ãƒƒã‚¯
                if st.session_state.get("text") and st.session_state.get("qa_questions") and st.session_state.get("qa_answers"):
                    payload = {"models": selected_models, "strategies": selected_strategies,
                               "text": st.session_state.text,
                               "questions": st.session_state.qa_questions,
                               "answers": st.session_state.qa_answers}
                    response = requests.post(f"{BACKEND_URL}/compare/", json=payload)
                    if response.status_code == 200:
                        st.success("æ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        st.write("æ¯”è¼ƒAPIã®è¿”å´å†…å®¹:", response.json())  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
                    else:
                        st.error(f"æ¯”è¼ƒã«å¤±æ•—ã—ã¾ã—ãŸ: {response.text}")
                else:
                    st.warning("PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨QAè‡ªå‹•ç”Ÿæˆã‚’å…ˆã«å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚æ¯”è¼ƒã¯è¡Œã„ã¾ã›ã‚“ã€‚")

