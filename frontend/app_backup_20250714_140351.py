from datetime import datetime
from pytz import timezone
import os
import json
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
import requests
import re
import traceback
from typing import List, Dict, Any, Optional, Union, Tuple
from dotenv import load_dotenv
import base64
import io
import zipfile
from pathlib import Path
import streamlit as st
import streamlit.components.v1 as components
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import matplotlib.font_manager as fm
import tempfile
import shutil
import matplotlib.pyplot as plt
from openai import OpenAI

def jst_now_str():
    return datetime.now(timezone('Asia/Tokyo')).strftime('%Y-%m-%d %H:%M:%S JST')

# ---# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
def get_japanese_font():
    """åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œå‡ºã—ã¦è¿”ã™"""
    try:
        # ä¸€èˆ¬çš„ãªæ—¥æœ¬èªå¯¾å¿œãƒ•ã‚©ãƒ³ãƒˆã®å„ªå…ˆé †ä½
        font_preferences = [
            'IPAexGothic', 'IPAGothic', 'Noto Sans CJK JP', 'Noto Sans JP',
            'Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Meiryo', 'MS Gothic',
            'Yu Gothic', 'TakaoGothic', 'VL Gothic', 'Arial Unicode MS', 'sans-serif'
        ]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—
        import matplotlib.font_manager as fm
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‹ã‚‰å„ªå…ˆé †ã«é¸æŠ
        for font in font_preferences:
            if any(font.lower() in f.lower() for f in available_fonts):
                return font
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ã‚»ãƒªãƒ•ãƒ•ã‚©ãƒ³ãƒˆ
        return 'sans-serif'
    except Exception as e:
        print(f"ãƒ•ã‚©ãƒ³ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return 'sans-serif'

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®š
japanese_font = get_japanese_font()

def plot_overlap_comparison(results_df: pd.DataFrame) -> None:
    """
    ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚ºã”ã¨ã®è©•ä¾¡æŒ‡æ¨™ã‚’å¯è¦–åŒ–ã™ã‚‹é–¢æ•°
    
    Args:
        results_df (pd.DataFrame): è©•ä¾¡çµæœãŒæ ¼ç´ã•ã‚ŒãŸDataFrame
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'download_charts' not in st.session_state:
        st.session_state.download_charts = False
        
    # å¿…è¦ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®šç¾©
    required_columns = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness', 'overall_score']
    available_metrics = [col for col in required_columns if col in results_df.columns]
    
    if not available_metrics:
        st.warning("æ¯”è¼ƒå¯èƒ½ãªè©•ä¾¡æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
        
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ã‚’æº–å‚™
        if 'overlap' not in results_df.columns and 'chunk_overlap' in results_df.columns:
            results_df['overlap'] = results_df['chunk_overlap']
        elif 'overlap' not in results_df.columns and 'contexts' in results_df.columns:
            try:
                results_df['overlap'] = results_df['contexts'].apply(
                    lambda x: len(' '.join(x).split()) - len(set(' '.join(x).split())) if x and len(x) > 0 else 0
                )
            except Exception as e:
                st.warning(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return
        
        if 'overlap' not in results_df.columns:
            st.warning("ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¯”è¼ƒã«ã¯'overlap'åˆ—ã¾ãŸã¯'chunk_overlap'åˆ—ãŒå¿…è¦ã§ã™ã€‚")
            return
        
        # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã«ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’æ±ºå®š
        group_cols = ['overlap']
        if 'embedding_model' in results_df.columns:
            group_cols.append('embedding_model')
        if 'chunk_strategy' in results_df.columns:
            group_cols.append('chunk_strategy')
        if 'chunk_size' in results_df.columns:
            group_cols.append('chunk_size')
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
        overlap_scores = results_df.groupby(group_cols)[available_metrics].mean().reset_index()
        
        if len(overlap_scores) <= 1:
            st.warning(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®å€¤ãŒ1ç¨®é¡ã—ã‹ã‚ã‚Šã¾ã›ã‚“ï¼ˆå€¤: {results_df['overlap'].iloc[0]}ï¼‰ã€‚æ¯”è¼ƒã«ã¯è¤‡æ•°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—å€¤ãŒå¿…è¦ã§ã™ã€‚")
            return
        
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    with tempfile.TemporaryDirectory() as tmp_dir:
        download_files = []
        
        # ã‚¿ãƒ–ã§è¤‡æ•°ã®å¯è¦–åŒ–ã‚’è¡¨ç¤º
        tab1, tab2, tab3 = st.tabs(["æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•", "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", "æœ€é©å€¤ã‚µãƒãƒªãƒ¼"])
        
        with tab1:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’é…ç½®
            if st.button("ğŸ“¥ ã‚°ãƒ©ãƒ•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="download_charts"):
                st.session_state.download_charts = True
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã”ã¨ã«å€‹åˆ¥ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            for metric in available_metrics:
                st.subheader(f"{metric} ã®æ¯”è¼ƒ")
                
                # ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ä¸¡æ–¹ã®æƒ…å ±ãŒã‚ã‚‹å ´åˆ
                if 'embedding_model' in group_cols and 'chunk_size' in group_cols:
                    models = overlap_scores['embedding_model'].unique()
                    chunk_sizes = sorted(overlap_scores['chunk_size'].unique())
                    
                    # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ã‚¿ãƒ–ã‚’ä½œæˆ
                    model_tabs = st.tabs([f"{model}" for model in models])
                    
                    for tab_idx, model in enumerate(models):
                        with model_tabs[tab_idx]:
                            model_data = overlap_scores[overlap_scores['embedding_model'] == model]
                            
                            # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã”ã¨ã«ç•°ãªã‚‹è‰²ã‚’å‰²ã‚Šå½“ã¦
                            colors = px.colors.qualitative.Plotly
                            
                            # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                            fig = go.Figure()
                            
                            # å„ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                            for i, chunk_size in enumerate(chunk_sizes):
                                size_data = model_data[model_data['chunk_size'] == chunk_size]
                                if len(size_data) > 0:
                                    color_idx = i % len(colors)
                                    
                                    fig.add_trace(go.Scatter(
                                        x=size_data['overlap'],
                                        y=size_data[metric],
                                        name=f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}",
                                        mode='lines+markers',
                                        line=dict(width=3, color=colors[color_idx]),
                                        marker=dict(size=10, color=colors[color_idx]),
                                        hovertemplate=f'<b>{model} (ãƒãƒ£ãƒ³ã‚¯: {chunk_size})</b><br>ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: %{{x}}<br>ã‚¹ã‚³ã‚¢: %{{y:.3f}}<extra></extra>',
                                        showlegend=True
                                    ))
                            
                            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                            fig.update_layout(
                                title=f"{model} - ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ¥æ¯”è¼ƒ",
                                xaxis_title="ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º (ãƒˆãƒ¼ã‚¯ãƒ³æ•°)",
                                yaxis_title=f"{metric} ã‚¹ã‚³ã‚¢ (0-1)",
                                template='plotly_white',
                                height=400,
                                margin=dict(l=50, r=50, t=80, b=50),
                                legend=dict(
                                    orientation='h',
                                    yanchor='bottom',
                                    y=1.02,
                                    xanchor='right',
                                    x=1,
                                    bgcolor='rgba(255,255,255,0.9)',
                                    bordercolor='rgba(0,0,0,0.2)',
                                    borderwidth=1
                                ),
                                xaxis=dict(
                                    showgrid=True,
                                    gridwidth=1,
                                    gridcolor='rgba(0,0,0,0.1)'
                                ),
                                yaxis=dict(
                                    range=[0, 1.05],
                                    showgrid=True,
                                    gridwidth=1,
                                    gridcolor='rgba(0,0,0,0.1)'
                                )
                            )
                            
                            # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
                            # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«ä¿å­˜
                            if st.session_state.download_charts:
                                if 'embedding_model' in group_cols and 'chunk_size' in group_cols:
                                    model_name = model.replace(" ", "_").replace("/", "-")
                                    filename = f"{metric}_model_{model_name}.png"
                                else:
                                    filename = f"{metric}.png"
                                
                                img_bytes = fig.to_image(format="png")
                                filepath = os.path.join(tmp_dir, filename)
                                with open(filepath, "wb") as f:
                                    f.write(img_bytes)
                                download_files.append(filepath)
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®ã¿ã‚ã‚‹å ´åˆ
                elif 'embedding_model' in group_cols:
                    # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç•°ãªã‚‹è‰²ã‚’å‰²ã‚Šå½“ã¦
                    colors = px.colors.qualitative.Plotly
                    
                    # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                    fig = go.Figure()
                    
                    # å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    for i, model in enumerate(overlap_scores['embedding_model'].unique()):
                        model_data = overlap_scores[overlap_scores['embedding_model'] == model]
                        color_idx = i % len(colors)
                        
                        fig.add_trace(go.Scatter(
                            x=model_data['overlap'],
                            y=model_data[metric],
                            name=model,
                            mode='lines+markers',
                            line=dict(width=3, color=colors[color_idx]),
                            marker=dict(size=10, color=colors[color_idx]),
                            hovertemplate=f'<b>{model}</b><br>ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: %{{x}}<br>ã‚¹ã‚³ã‚¢: %{{y:.3f}}<extra></extra>'
                        ))
                    
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                    fig.update_layout(
                        xaxis_title="ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º (ãƒˆãƒ¼ã‚¯ãƒ³æ•°)",
                        yaxis_title=f"{metric} ã‚¹ã‚³ã‚¢ (0-1)",
                        template='plotly_white',
                        height=400,
                        margin=dict(l=50, r=50, t=50, b=50),
                        legend=dict(
                            orientation='h',
                            yanchor='bottom',
                            y=1.02,
                            xanchor='right',
                            x=1,
                            bgcolor='rgba(255,255,255,0.9)',
                            bordercolor='rgba(0,0,0,0.2)',
                            borderwidth=1
                        ),
                        xaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='rgba(0,0,0,0.1)'
                        ),
                        yaxis=dict(
                            range=[0, 1.05],
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='rgba(0,0,0,0.1)',
                            showline=True,
                            linewidth=2,
                            linecolor='black',
                            mirror=True,
                            ticks='outside',
                            tickwidth=2,
                        )
                    )

                    # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
                    st.plotly_chart(fig, use_container_width=True)

                # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä¿å­˜å‡¦ç†
                if st.session_state.download_charts and 'heatmap_filename' in locals():
                    filepath = os.path.join(tmp_dir, heatmap_filename)
                    img_bytes = fig.to_image(format="png")
                    with open(filepath, "wb") as f:
                        f.write(img_bytes)
                    download_files.append(filepath)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«ä¿å­˜
                    filename = f"{metric}_all_models.png"
                    img_bytes = fig.to_image(format="png")
                    filepath = os.path.join(tmp_dir, filename)
{{ ... }}
                        st.error("è©•ä¾¡å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        return None
                        
                    if not qa_questions or not qa_answers:
                        st.error("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€Q&Aã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                        # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
                # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
        with tab3:
            if 'summary_df' in locals() and not summary_df.empty:
                st.dataframe(
                    summary_df,
                    column_config={
                        "embedding_model": "ãƒ¢ãƒ‡ãƒ«",
                        "chunk_strategy": "ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥",
                        "chunk_size": "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º",
                        "overlap": "æœ€é©ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—",
                        **{col: st.column_config.NumberColumn(col, format="%.3f") for col in available_metrics}
                    },
                    hide_index=True,
                    use_container_width=True
                )
                
                # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv = summary_df.to_csv(index=False, encoding='utf-8-sig')
                b64 = base64.b64encode(csv.encode('utf-8-sig')).decode()
                href = f'<a href="data:text/csv;charset=utf-8-sig;base64,{b64}" download="summary_table.csv">ğŸ“¥ ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)</a>'
                st.markdown(href, unsafe_allow_html=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†
        if st.session_state.download_charts and download_files:
            with st.spinner("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ä¸­..."):
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                zip_buffer = io.BytesIO()
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in download_files:
                        if os.path.exists(file_path):
                            zipf.write(file_path, os.path.basename(file_path))
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
                if zip_buffer.getbuffer().nbytes > 0:
                    b64 = base64.b64encode(zip_buffer.getvalue()).decode()
                    href = f'<a href="data:application/zip;base64,{b64}" download="overlap_comparison_charts.zip">ğŸ“¥ ã‚°ãƒ©ãƒ•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)</a>'
                    st.markdown(href, unsafe_allow_html=True)
                    st.session_state.download_charts = False
                    
                    response = requests.post(
                        f"{BACKEND_URL}/bulk_evaluate/", 
                        json=payload, 
{{ ... }}
                        timeout=300
                    )
                    
                    completed_tasks[0] += 1
                    progress_bar.progress(min(completed_tasks[0] / total_tasks, 1.0))
                    progress_text.text(f"å®Œäº†: {completed_tasks[0]} / {total_tasks} ä»¶")
                    
                    if response.status_code == 200:
                        result = response.json()
                        
                        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãƒªã‚¹ãƒˆã®å ´åˆã¯æœ€åˆã®è¦ç´ ã‚’å–å¾—
                        if isinstance(result, list):
                            if len(result) > 0:
                                result = result[0]
                            else:
                                result = {}
                        
                        # çµæœãŒè¾æ›¸ã§ãªã„å ´åˆã¯è¾æ›¸ã«å¤‰æ›
                        if not isinstance(result, dict):
                            result = {}
                        
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        result['embedding_model'] = emb
                        result['chunk_method'] = method
                        result['chunk_size'] = size
                        result['chunk_overlap'] = overlap
                        
                        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                        if 'overlap' not in result:
                            result['overlap'] = overlap if overlap is not None else 0
                            
                        return result
                    else:
                        st.error("è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°:")
                        st.json({
                            "status_code": response.status_code,
                            "error": response.text,
                            "request_payload": payload
                        })
                        return None
                        
                except requests.exceptions.RequestException as e:
                    st.error(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return None
                except json.JSONDecodeError as e:
                    st.error(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return None
                except Exception as e:
                    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    import traceback
                    st.text(traceback.format_exc())
                    return None
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨: ä¸¦åˆ—å‡¦ç†ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            bulk_results = []
            
            try:
                for emb in selected_embeddings:
                    for method, size, overlap in valid_combinations:
                        # ç¾åœ¨ã®è©•ä¾¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
                        status_display.info(f"è©•ä¾¡ä¸­: {emb}, {method}, size={size}, overlap={overlap}")
                        
                        # è©•ä¾¡ã‚’å®Ÿè¡Œ
                        result = evaluate_single(emb, method, size, overlap)
                        
                        if result:
                            bulk_results.append(result)
                            status_display.success(f"å®Œäº†: {emb}, {method}, size={size}, overlap={overlap}")
                        else:
                            status_display.warning(f"ã‚¹ã‚­ãƒƒãƒ—: {emb}, {method}, size={size}, overlap={overlap}")
                        
                        # å°‘ã—å¾…æ©Ÿï¼ˆUIã®æ›´æ–°ã®ãŸã‚ï¼‰
                        import time
                        time.sleep(0.1)
                
                # æœ€çµ‚çš„ãªé€²æ—è¡¨ç¤º
                progress_text.success(f"å®Œäº†: {total_tasks} / {total_tasks} ä»¶")
                
                # é€²æ—ãƒãƒ¼ã‚’100%ã«
                progress_bar.progress(1.0)
                
                # æœ€çµ‚çš„ãªã‚µãƒãƒªã‚’è¡¨ç¤º
                if bulk_results:
                    status_display.success(f"è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ (æˆåŠŸ: {len(bulk_results)}ä»¶)")
                else:
                    status_display.error("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ‰åŠ¹ãªçµæœã¯å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            except Exception as e:
                status_display.error(f"è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            if bulk_results:
                try:
                    # çµæœãŒãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã®å ´åˆã«ãƒ•ãƒ©ãƒƒãƒˆåŒ–
                    flat_results = []
                    for result in bulk_results:
                        if isinstance(result, list):
                            flat_results.extend(result)
                        else:
                            flat_results.append(result)
                    
                    st.session_state.bulk_evaluation_results = flat_results
                    
                    # çµæœã®è©³ç´°ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
                    if bulk_results:
                        print("\n=== è©•ä¾¡çµæœã‚µãƒãƒª ===")
                        print(f"æˆåŠŸ: {len(bulk_results)}ä»¶")
                        for i, result in enumerate(bulk_results, 1):
                            print(f"\n--- çµæœ {i} ---")
                            print(json.dumps(result, ensure_ascii=False, indent=2))
                except Exception as e:
                    if 'status_text' in locals():
                        status_text.error(f"çµæœã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


    if st.session_state.bulk_evaluation_results:
        st.subheader("ä¸€æ‹¬è©•ä¾¡çµæœ")
        st.write("ä¸€æ‹¬è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.bulk_evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        eval_results = st.session_state.bulk_evaluation_results
        
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ
        if isinstance(eval_results, list):
            results_df = pd.DataFrame(eval_results)
        else:
            results_df = pd.DataFrame([eval_results])
        
        # ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’å±•é–‹
        if 'scores' in results_df.columns:
            # ã‚¹ã‚³ã‚¢ãŒè¾æ›¸å½¢å¼ã§æ ¼ç´ã•ã‚Œã¦ã„ã‚‹å ´åˆã€å„ã‚¹ã‚³ã‚¢ã‚’å€‹åˆ¥ã®ã‚«ãƒ©ãƒ ã«å±•é–‹
            scores_df = pd.json_normalize(results_df['scores'])
            # å…ƒã®ã‚«ãƒ©ãƒ ã¨çµåˆï¼ˆæ¥é ­è¾ã‚’ä»˜ã‘ã¦ç«¶åˆã‚’é¿ã‘ã‚‹ï¼‰
            results_df = pd.concat([results_df.drop('scores', axis=1), scores_df.add_prefix('score_')], axis=1)
        
        # å¿…è¦ã‚«ãƒ©ãƒ è£œå®Œãƒ»ãƒ©ãƒ™ãƒ«åˆ—è¿½åŠ 
        required_cols = {
            'avg_chunk_len', 'num_chunks', 'overall_score', 'chunk_strategy', 'embedding_model',
            'faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness'
        }
        
        # ã‚¹ã‚³ã‚¢ã‚«ãƒ©ãƒ ã®è£œå®Œï¼ˆscore_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒä»˜ã„ã¦ã„ã‚‹å ´åˆã«å¯¾å¿œï¼‰
        for col in ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'answer_correctness', 'overall_score']:
            if f'score_{col}' in results_df.columns and col not in results_df.columns:
                results_df[col] = results_df[f'score_{col}']
        
        missing_cols = required_cols - set(results_df.columns)
        
        if 'chunk_method' in results_df.columns and 'chunk_strategy' not in results_df.columns:
            results_df['chunk_strategy'] = results_df['chunk_method']
            st.info('chunk_strategyåˆ—ã‚’chunk_methodã‹ã‚‰è£œå®Œã—ã¾ã—ãŸ')
        
        if len(results_df) > 0:
            # ä¸è¶³ã‚«ãƒ©ãƒ ã®è£œå®Œ
            if missing_cols:
                st.info(f'ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆç”¨ã®ã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}ã€‚è‡ªå‹•ã§ä»®å€¤ã‚’è£œå®Œã—ã¾ã™ã€‚')
                for col in missing_cols:
                    if col == 'chunk_strategy':
                        results_df[col] = 'unknown'
                    else:
                        results_df[col] = 0.0
            
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æƒ…å ±ã‚’è¿½åŠ ï¼ˆchunk_overlapã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦ä½¿ç”¨ï¼‰
            if 'overlap' not in results_df.columns and 'chunk_overlap' in results_df.columns:
                results_df['overlap'] = results_df['chunk_overlap']
            
            # ãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ ï¼ˆchunk_sizeãŒã‚ã‚Œã°å«ã‚ã‚‹ï¼‰
            if 'chunk_size' in results_df.columns:
                results_df['label'] = results_df['chunk_strategy'] + '-' + results_df['chunk_size'].astype(str)
            else:
                results_df['label'] = results_df['chunk_strategy']
        
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ¯”è¼ƒã‚’è¡¨ç¤º
        if 'overlap' in results_df.columns and len(results_df['overlap'].unique()) > 1:
            plot_overlap_comparison(results_df)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãã®æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å®šç¾©
            metrics = ["faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]
            metrics_jp = ["ä¿¡é ¼æ€§", "å›ç­”ã®é–¢é€£æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å†ç¾æ€§", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ­£ç¢ºæ€§", "å›ç­”ã®æ­£ç¢ºæ€§"]
            
            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            if 'embedding_model' in results_df.columns:
                model_groups = list(results_df.groupby('embedding_model'))
            else:
                model_groups = [('default', results_df)]

            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            for model_name, model_data in model_groups:
                if not model_data.empty and 'chunk_size' in model_data.columns and 'overall_score' in model_data.columns:
                    # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                    if 'num_chunks' not in model_data.columns:
                        model_data['num_chunks'] = 0
                    if 'avg_chunk_len' not in model_data.columns:
                        model_data['avg_chunk_len'] = 0
                    if 'overall_score' not in model_data.columns:
                        model_data['overall_score'] = 0
                    
                    # ãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆ0é™¤ç®—ã‚’é˜²ãï¼‰
                    bubble_sizes = [min(s * 20, 50) if pd.notnull(s) else 5 for s in model_data["overall_score"]]
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆå…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ï¼‰
                    plot_data = model_data.copy()
                    plot_data['bubble_size'] = bubble_sizes
                    
                    fig_bubble = px.scatter(
                        data_frame=plot_data,
                        x="num_chunks",
                        y="avg_chunk_len",
                        size="bubble_size",
                        color="overall_score",
                        hover_data={
                            "chunk_size": True,
                            "chunk_strategy": True,
                            "num_chunks": True,
                            "avg_chunk_len": ":.1f",
                            "overall_score": ".3f"
                        },
                        labels={
                            "num_chunks": "ãƒãƒ£ãƒ³ã‚¯æ•°",
                            "avg_chunk_len": "å¹³å‡ãƒãƒ£ãƒ³ã‚¯é•·",
                            "overall_score": "ç·åˆã‚¹ã‚³ã‚¢"
                        },
                        color_continuous_scale=px.colors.sequential.Viridis,
                        width=1200,  # ã‚°ãƒ©ãƒ•ã®å¹…ã‚’æ‹¡å¤§
                        height=800,  # ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’æ‹¡å¤§
                        color_continuous_midpoint=0.5,
                    )
                    
                    # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ›´æ–°
                    fig_bubble.update_traces(
                        textposition='middle center',
                        textfont=dict(size=12, color='white', family='Arial'),
                        marker=dict(line=dict(width=1, color='DarkSlateGrey'), opacity=0.8),
                        hovertemplate=
                        '<b>%{hovertext}</b><br>' +
                        'ãƒãƒ£ãƒ³ã‚¯æ•°: %{x}<br>' +
                        'å¹³å‡ã‚µã‚¤ã‚º: %{y}æ–‡å­—<br>' +
                        'ã‚¹ã‚³ã‚¢: %{marker.color:.2f}<extra></extra>',
                    )
                    
                    fig_bubble.update_layout(
                        title={
                            'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯åˆ†å¸ƒã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                            'x': 0.5,
                            'xanchor': 'center'
                        },
                        coloraxis_colorbar=dict(title="ã‚¹ã‚³ã‚¢"),
                        font=dict(size=14),
                        height=500,
                        margin=dict(l=40, r=40, t=80, b=40)
                    )
                    
                    st.plotly_chart(fig_bubble, use_container_width=True)
                    st.markdown('<br>', unsafe_allow_html=True)
            
            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            for model_name, model_data in model_groups:
                if not model_data.empty and 'chunk_strategy' in model_data.columns and 'overall_score' in model_data.columns:
                    # ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é›†è¨ˆ
                    strategy_scores = model_data.groupby('chunk_strategy')['overall_score'].mean().sort_values(ascending=False)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
                    bar_data = pd.DataFrame({
                        'strategy': strategy_scores.index,
                        'score': strategy_scores.values,
                        'score_text': [f"{x:.3f}" for x in strategy_scores.values]
                    })
                    
                    # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
                    fig_bar = px.bar(
                        data_frame=bar_data,
                        x='score',
                        y='strategy',
                        orientation='h',
                        text='score_text',
                        title=f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                        labels={'score': 'å¹³å‡ã‚¹ã‚³ã‚¢', 'strategy': 'ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥'},
                        color='score',
                        color_continuous_scale=px.colors.sequential.Viridis,
                        width=1200,  # ã‚°ãƒ©ãƒ•ã®å¹…ã‚’æ‹¡å¤§
                        height=800,  # ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’æ‹¡å¤§
                    )
                    
                    # ãƒãƒ¼ã®ä¸Šã«ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                    fig_bar.update_traces(
                        texttemplate='%{x:.3f}',
                        textposition='outside',
                        hovertemplate='<b>%{y}</b><br>ã‚¹ã‚³ã‚¢: %{x:.3f}<extra></extra>',
                    )
                    
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                    fig_bar.update_layout(
                        title={
                            'text': f"{model_name} - ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                            'x': 0.5,
                            'xanchor': 'center',
                            'font': {'size': 18}
                        },
                        xaxis=dict(range=[0, 1.1]),
                        coloraxis_showscale=False,
                        height=400,
                        margin=dict(l=100, r=40, t=100, b=40),
                        yaxis=dict(autorange="reversed"),
                        font=dict(size=14)
                    )
                    
                    # ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
                    st.plotly_chart(fig_bar, use_container_width=True)
                    st.markdown('<br>', unsafe_allow_html=True)
            
            # ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã”ã¨ã«ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            if 'chunk_strategy' in results_df.columns:
                chunk_strategies = results_df['chunk_strategy'].unique()
                
                for strategy in chunk_strategies:
                    strategy_data = results_df[results_df['chunk_strategy'] == strategy]
                    
                    if not strategy_data.empty:
                        st.subheader(f"{strategy} - è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ")
                        fig_radar = go.Figure()
                        
                        # å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        for model_name, model_data in model_groups:
                            model_strategy_data = strategy_data[strategy_data['embedding_model'] == model_name] if 'embedding_model' in strategy_data.columns else strategy_data
                            
                            if not model_strategy_data.empty:
                                # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¹³å‡å€¤ã‚’è¨ˆç®—
                                r_values = [model_strategy_data[m].mean() if m in model_strategy_data.columns else 0.5 for m in metrics]
                                
                                fig_radar.add_trace(go.Scatterpolar(
                                    r=r_values,
                                    theta=metrics_jp,
                                    fill='toself',
                                    name=model_name,
                                    hovertemplate='%{theta}: %{r:.2f}<extra></extra>',
                                    line=dict(width=2)
                                ))
                        
                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
                        fig_radar.update_layout(
                            polar=dict(
                                radialaxis=dict(
                                    visible=True,
                                    range=[0, 1],
                                    tickfont=dict(size=10),
                                    tickangle=0,
                                    tickformat='.1f',
                                    gridwidth=1
                                ),
                                angularaxis=dict(
                                    rotation=90,
                                    direction='clockwise',
                                    tickfont=dict(size=12),
                                    gridwidth=1
                                ),
                                bgcolor='rgba(0,0,0,0.02)'
                            ),
                            showlegend=True,
                            legend=dict(
                                orientation='h',
                                yanchor='bottom',
                                y=1.15,
                                xanchor='center',
                                x=0.5,
                                font=dict(size=12)
                            ),
                            margin=dict(l=60, r=60, t=30, b=60),  # ä¸Šéƒ¨ãƒãƒ¼ã‚¸ãƒ³ã‚’å°ã•ãèª¿æ•´
                            height=500,
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)'
                        )
                        
                        st.plotly_chart(fig_radar, use_container_width=True)
                        st.markdown('<br>', unsafe_allow_html=True)
            
            # çµæœã‚’DataFrameã«å¤‰æ›
        results_df = pd.DataFrame(st.session_state.bulk_evaluation_results)
        
        # ã‚°ãƒ©ãƒ•ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
        st.markdown("---")
        st.subheader("ã‚°ãƒ©ãƒ•ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
        st.markdown("""
        <style>
            .stDownloadButton button {
                width: 100%;
                height: 3em;
                font-size: 1.2em !important;
                background-color: #4CAF50;
                color: white;
                border: none;
                border-radius: 5px;
                cursor: pointer;
                transition: background-color 0.3s;
            }
            .stDownloadButton button:hover {
                background-color: #45a049;
            }
            .stDownloadButton button:active {
                background-color: #3e8e41;
            }
        </style>
        """, unsafe_allow_html=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        if st.button("ğŸ“¥ ã™ã¹ã¦ã®ã‚°ãƒ©ãƒ•ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="download_all_graphs"):
            with st.spinner("ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã¦ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                zip_data = create_zip_with_graphs(st.session_state.bulk_evaluation_results, "rag_evaluation_graphs")
                
                if zip_data:
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ
                    b64 = base64.b64encode(zip_data).decode()
                    href = f'<a href="data:application/zip;base64,{b64}" download="rag_evaluation_graphs.zip" class="download-link">ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
                    st.markdown(href, unsafe_allow_html=True)
                    st.success("ã‚°ãƒ©ãƒ•ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.error("ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

with tab4:
    if 'uploaded_file_bytes' not in st.session_state:
        st.warning("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    st.header("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
    
    if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:
        st.subheader("è©•ä¾¡çµæœã®æ¯”è¼ƒ")
        
        # è©•ä¾¡çµæœã‚’DataFrameã«å¤‰æ›
        eval_results = st.session_state.evaluation_results
        if 'results' in eval_results:
            df_data = []
            for i, result in enumerate(eval_results['results']):
                row = {
                    'è³ªå•ç•ªå·': i+1,
                    'è³ªå•': result.get('question', ''),
                    'å›ç­”': result.get('answer', '')
                }
                if 'details' in result:
                    for k, v in result['details'].items():
                        if isinstance(v, (int, float)):
                            row[k] = v
                df_data.append(row)
            
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(df)
                
                # ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–
                score_cols = [col for col in df.columns if col not in ['è³ªå•ç•ªå·', 'è³ªå•', 'å›ç­”']]
                if score_cols:
                    st.subheader("ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ")
                    fig = px.bar(df, x='è³ªå•ç•ªå·', y=score_cols, 
                                title="è³ªå•ã”ã¨ã®ã‚¹ã‚³ã‚¢æ¯”è¼ƒ",
                                labels={'value': 'ã‚¹ã‚³ã‚¢', 'variable': 'è©•ä¾¡é …ç›®', 'è³ªå•ç•ªå·': 'è³ªå•ç•ªå·'})
                    st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("æ¯”è¼ƒã™ã‚‹è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡ã¾ãŸã¯ä¸€æ‹¬è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        # --- è‡ªå‹•ç”ŸæˆQAã‚»ãƒƒãƒˆå„ªå…ˆã§åˆ©ç”¨ ---
        auto_questions = st.session_state.get('qa_questions', None)
        auto_answers = st.session_state.get('qa_answers', None)
        if auto_questions:
            st.markdown("#### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¾ã™")
            questions = auto_questions
            st.write("\n".join([f"Q{i+1}: {q}" for i, q in enumerate(questions)]))
        else:
            questions_input = st.text_area("1è¡Œã«1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150, 
                                           value="ä¸»ãªãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æŠ€è¡“ã«ã¯ä½•ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨å†å¸°çš„æ–‡å­—åˆ†å‰²ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ")
            questions = [q.strip() for q in questions_input.split('\n') if q.strip()]

        if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ", key="evaluate_button_evaluation"):
            if not questions:
                st.warning("æœ€ä½1ã¤ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("è©•ä¾¡ã‚’å®Ÿè¡Œä¸­... ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"):
                    try:
                        # 1. è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                        answers = []
                        contexts = []
                        # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Œã°åˆ©ç”¨ ---
                        if auto_answers and len(auto_answers) == len(questions):
                            answers = auto_answers
                            st.success("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                        else:
                            # å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¿½åŠ 
                            st.warning("è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            st.stop()

                        # 2. è©•ä¾¡ã‚’å®Ÿè¡Œ
                        evaluation_payload = {
                            "questions": questions,
                            "answers": answers,
                            "contexts": ["" for _ in questions],  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ç©ºã§ä»®è¨­å®š
                            "model": st.session_state.llm_model
                        }
                        
                        eval_response = requests.post(f"{BACKEND_URL}/evaluate/", json=evaluation_payload)
                        if eval_response.status_code == 200:
                            st.session_state.evaluation_results = eval_response.json()
                            st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            # è©•ä¾¡çµæœã‚’è¡¨ç¤ºã™ã‚‹ã‚¿ãƒ–ã«ç§»å‹•
                            st.session_state.active_tab = "è©•ä¾¡"
                            st.rerun()
                        else:
                            st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {eval_response.text}")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.warning(f"chunk_size <= overlap ã¨ãªã‚‹ä¸æ­£ãªçµ„ã¿åˆã‚ã›ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã—ãŸ: ({embedding}, {strategy}, {size}, {overlap})")
                    # é€²æ—ãƒãƒ¼ã®è¨­å®š
                    progress_bar = st.progress(0)
                    total_tasks = len(futures)
                    completed_tasks = 0
                    for future in concurrent.futures.as_completed(futures):
                        result = future.result()
                        if result is not None:
                            answers.append(result['answer'])
                            contexts.append(result['context'])
                        completed_tasks += 1
                        progress_bar.progress(min(completed_tasks / total_tasks, 1.0))
                    progress_bar.empty()
                    st.session_state.evaluation_results = {"answers": answers, "contexts": contexts}
                    st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        if st.session_state.evaluation_results:
            st.subheader("è©•ä¾¡æŒ‡æ¨™")
            st.write("è©•ä¾¡APIã®è¿”å´å†…å®¹:", st.session_state.evaluation_results)  # è¿”å´å†…å®¹ã‚’ç¢ºèªç”¨ã«è¡¨ç¤º
            # evaluation_resultsãŒãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆã«å¯¾å¿œ
            eval_results = st.session_state.evaluation_results
            if isinstance(eval_results, list):
                results_df = pd.DataFrame(eval_results)
            else:
                results_df = pd.DataFrame([eval_results])
            # è‹±èªâ†’æ—¥æœ¬èªã®æŒ‡æ¨™åãƒãƒƒãƒ”ãƒ³ã‚°
            METRIC_JA = {
                "faithfulness": "ãƒ•ã‚¡ã‚¯ãƒˆæ•´åˆæ€§",
                "answer_relevancy": "å›ç­”é–¢é€£æ€§",
                "context_recall": "æ–‡è„ˆå†ç¾ç‡",
                "context_precision": "æ–‡è„ˆé©åˆç‡"
            }

            # DataFrameã®ã‚«ãƒ©ãƒ åã‚‚æ—¥æœ¬èªã«å¤‰æ›ã—ã¦è¡¨ç¤º
            results_df_ja = results_df.rename(columns=METRIC_JA)
            st.dataframe(results_df_ja)

            # Plotting
            metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
            available_metrics = [m for m in metrics if m in results_df.columns]

            if available_metrics:
                plot_df = results_df[available_metrics].T.reset_index()
                plot_df['index'] = plot_df['index'].map(METRIC_JA)
                plot_df.columns = ['æŒ‡æ¨™', 'ã‚¹ã‚³ã‚¢']

                # Performance Rankingé¢¨ æ¨ªæ£’ã‚°ãƒ©ãƒ•
                fig_bar = px.bar(
                    plot_df,
                    y='æŒ‡æ¨™',
                    x='ã‚¹ã‚³ã‚¢',
                    orientation='h',
                    text='ã‚¹ã‚³ã‚¢',
                    title="Performance Ranking",
                    labels={"æŒ‡æ¨™": "Metric", "ã‚¹ã‚³ã‚¢": "Score"},
                )
                fig_bar.update_traces(texttemplate='%{x:.3f}', textposition='outside')
                fig_bar.update_layout(
                    title={
                        'text': "RAG Strategy Performance Ranking<br><sup>Error bars show standard deviation â€¢ * indicates statistical significance</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    font=dict(size=16),
                    height=550,
                    margin=dict(l=40, r=40, t=80, b=40),
                    showlegend=False
                )
                st.plotly_chart(fig_bar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_bar:
                    st.session_state['eval_figs'].append(fig_bar)
                st.markdown('<br>', unsafe_allow_html=True)

                # RAGAS Metrics Comparisoné¢¨ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
                import plotly.graph_objects as go
                metrics_en = ['Faithfulness', 'Answer Relevancy', 'Context Recall', 'Context Precision']
                metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']
                r_values = [results_df[m].iloc[0] if m in results_df.columns else 0 for m in metrics]
                fig_radar = go.Figure()
                fig_radar.add_trace(go.Scatterpolar(
                    r=r_values,
                    theta=metrics_en,
                    fill='toself',
                    name='Sample'
                ))
                fig_radar.update_layout(
                    title={
                        'text': "RAGAS Metrics Comparison<br><sup>All metrics normalized to 0-1 scale</sup>",
                        'x':0.5,
                        'xanchor': 'center'
                    },
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    showlegend=True,
                    font=dict(size=16),
                    height=600,
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                st.plotly_chart(fig_radar, use_container_width=True)
                if 'eval_figs' not in st.session_state:
                    st.session_state['eval_figs'] = []
                if len(st.session_state['eval_figs']) == 0 or st.session_state['eval_figs'][-1] != fig_radar:
                    st.session_state['eval_figs'].append(fig_radar)
                st.markdown('<br>', unsafe_allow_html=True)
            else:
                st.warning("è©•ä¾¡æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡APIã®è¿”å´å†…å®¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¿ãƒ–
with tab_chatbot:
    st.header("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ã‚’ç”Ÿæˆ
        response_text = ""
        with st.chat_message("assistant"):
            try:
                if not os.getenv("OPENAI_API_KEY"):
                    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    response_text = "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™
                messages = [{"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}]
                messages.extend([{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_messages])
                
                # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦APIã‚’å‘¼ã³å‡ºã—
                if st.session_state.chat_model in ["gpt-4o-mini", "gpt-3.5-turbo"]:
                    # OpenAI APIã‚’ä½¿ç”¨
                    api_key = os.getenv("OPENAI_API_KEY")
                    if not api_key:
                        response_text = "ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                    else:
                        try:
                            client = OpenAI(api_key=api_key)
                            response = client.chat.completions.create(
                                model=st.session_state.chat_model,
                                messages=messages,
                                temperature=0.7,
                                max_tokens=1000
                            )
                            response_text = response.choices[0].message.content
                        except Exception as e:
                            response_text = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                else:
                    # ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼ˆä¾‹ã¨ã—ã¦ã®å®Ÿè£…ï¼‰
                    response_text = f"{st.session_state.chat_model} ã‹ã‚‰ã®å¿œç­”: ã‚ãªãŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€Œ{prompt}ã€ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n\nï¼ˆæ³¨: ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼å¿œç­”ã§ã™ï¼‰"
                
                st.markdown(response_text)
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.chat_messages.append({"role": "assistant", "content": response_text})
                
            except Exception as e:
                error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_msg)
                st.session_state.chat_messages.append({"role": "assistant", "content": error_msg})
        
        # ç”»é¢ã‚’æ›´æ–°
        st.rerun()